% !TeX spellcheck = cs_CZ
\documentclass[czech,master,dept460,male,csharp,cpdeclaration]{diploma}

\usepackage[autostyle=true,czech=quotes]{csquotes} % korektni sazba uvozovek, podpora pro balik biblatex
\usepackage[backend=bibtex, style=iso-numeric, alldates=iso]{biblatex} % bibliografie
\usepackage{dcolumn} % sloupce tabulky s ciselnymi hodnotami
\usepackage{subfig} % makra pro "podobrazky" a "podtabulky"
\usepackage{rotating}
\usepackage{float}

\usepackage{geometry}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pgfplots}

\usepackage{xcolor}
\usepackage{listings}
%\usepackage{mathtools} %- blokuje list obrázků a tabulek

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
	basicstyle=\normalfont\ttfamily,
	numbers=left,
	numberstyle=\scriptsize,
	stepnumber=1,
	numbersep=8pt,
	showstringspaces=false,
	breaklines=true,
	frame=lines,
	backgroundcolor=\color{background},
	literate=
	*{3}{{{\color{numb}3}}}{1}
	{5}{{{\color{numb}5}}}{1}
	{:}{{{\color{punct}{:}}}}{1}
	{,}{{{\color{punct}{,}}}}{1}
	{\{}{{{\color{delim}{\{}}}}{1}
	{\}}{{{\color{delim}{\}}}}}{1}
	{[}{{{\color{delim}{[}}}}{1}
	{]}{{{\color{delim}{]}}}}{1},
}



\ThesisAuthor{Bc. Jan Jedlička}

\ThesisSupervisor{prof. Ing. Michal Krátký, Ph.D.}

\CzechThesisTitle{Key-value databázové systémy}

\EnglishThesisTitle{Key-value database systems}

\SubmissionYear{2024}

\ThesisAssignmentFileName{ThesisSpecification_JED0050_vsboee2302B326.pdf}

\Acknowledgement{Na tomto místě bych chtěl poděkovat vedoucímu této práce prof. Ing. Michalovi Krátkému, Ph.D., za poskytnutí užitečných rad a pomoci vedením práce.}

\CzechAbstract{Cílem diplomové práce je popsat Key-value databázové systémy (KDBS), ukázat výhody a nevýhody těchto databázových systémů (DBS) a představit některé významné zástupce. První část práce je zaměřena nejen na obecný popis KDBS, ale i na podrobnější popis vybraných KDBS a jejich vzájemné porovnání. Součástí práce je zmapování existujících testů DBS a následný výběr a zprovoznění testovacího prostředí pro testování těchto systémů a porovnání s ostatními DBS. Práce popisuje dva významné představitele testovacích prostředí DBS, YCSB a TPC. S prostředím YCSB se v práci následně pracuje a testují se v něm čtyři vybrané KDBS: Redis, Aerospike, Riak KV a Memcached. YCSB testy jsou spouštěny pomocí skriptů, které nejprve spustí a nastaví DBS v prostředí Docker. Práce je zakončena prezentací hodnot naměřených při testování, vyhodnocením výsledků a srovnáním výkonu KDBS.}

\CzechKeywords{DBS; NoSQL; Key-value DBS; Benchmarking; YCSB; TPC; Redis; Riak KV; Aerospike; Memcached}

\EnglishAbstract{The aim of this thesis is to describe Key-value database systems (KDBS), to show the advantages and disadvantages of these database systems (DBS) and to introduce some important representatives. The first part of the thesis focuses not only on a general description of KDBSs, but also on more detailed specifications of selected KDBSs and their comparison with each other. The work includes a study of existing DBSs and then the selection and commissioning of a testbed for testing these systems
and comparing them with other DBSs. The thesis describes two prominent representatives of DBS test environments, YCSB and TPC. The YCSB environment is then used in the thesis to test four selected KDBSs: Redis, Aerospike, Riak KV and Memcached. The YCSB tests are run using scripts that first start and set up the DBS in the Docker environment. The paper concludes by presenting the values measured during testing, evaluating the results and comparing the performance of the KDBS.}

\EnglishKeywords{DBS; NoSQL; Key-value DBS; Benchmarking; YCSB; TPC; Redis; Riak KV; Aerospike; Memcached}

\AddAcronym{DBS}{databázový systém (database system)}
\AddAcronym{NoSQL}{Not only Structured Query Language}
\AddAcronym{Key-value DBS}{databázový systém typu klíč-hodnota}
\AddAcronym{KDBS}{databázový systém typu klíč-hodnota}
\AddAcronym{RDBS}{relační DBS}
\AddAcronym{JSON}{JavaScript Object Notation}
\AddAcronym{TTL}{Time to live}
\AddAcronym{TPC}{Transaction Processing Performance Council}
\AddAcronym{YCSB}{Yahoo! Cloud Serving Benchmark}
\AddAcronym{kops}{tisíc operací}
\AddAcronym{Workload}{vytížení}

\addbibresource{citace.bib}

\begin{document}
	
	\MakeTitlePages
	
	\listoffigures
	\listoftables
	
	\chapter{Úvod}
	
	Key-value (neboli Klíč-hodnota) databázové systémy~\cite{amaz-key-value-db, ytb-nosql-db}, dále jen KDBS, jsou jedním z typů NoSQL DBS~\cite{nosql}. Tyto databázové systémy jsou navrženy pro uživatelsky přívětivý přístup k datům pomocí elementárních příkazů (CRUD~\cite{crud}). Základním dotazem pro práci s daty je přístup k hodnotám v databázi prostřednictvím klíčů. V KDBS se hodnota ukládá k danému klíči, přičemž klíč může být například "jmeno\_uzivatele\_03"~a hodnota může být řetězec "Jan Novák". Datovým typem hodnot mohou být také čísla, booleovské hodnoty, binární data, seznamy a v případě komplexních dat i JSON dokumenty~\cite{json}. Klíč "detail\_uzivatele\_03"~může pak, jako hodnotu ukládat, například JSON dokument vybraného uživatele popisující jeho jméno, věk, adresu nebo kontakt (viz JSON dokument na obrázku~\ref{json-hodnota}).
	
	\begin{figure}
	\centering
	\begin{lstlisting}[language=json,firstnumber=1]
{
  "jmeno": "Jan Novak",
   "vek": 35,
   "adresa": null,
   "kontakt": [
      {"email": "jan.novak.01@gmail.com"},
      {"telefon": "406-792-448"}
   ]
}
	\end{lstlisting}
	\caption{Příklad JSON dokumentu uloženého jako hodnota pro klíč "detail\_uzivatele\_03"}
	\label{json-hodnota}
	\end{figure}	
	
	KDBS fungují odlišně oproti tradičním relačním databázovým systémům. Datový model RDBS je relační~\cite{rdbs}, což znamená, že data jsou organizována do tabulek, kde každá tabulka představuje jednu relaci~\cite{relace} a každý záznam v tabulce odpovídá jednomu prvku relace. Každá tabulka obsahuje atributy, které předem pevně definují svůj datové typy. Jeden nebo více atributů může být primární klíč, který jednoznačně identifikuje každý záznam. Tento relační model poskytuje snadný přístup k ukládání a manipulaci s relacemi, což usnadňuje vyhledávání informací. RDBS umožňuje provádět řadu optimalizací, jako je například přidávání vlastních indexů nebo změna plánování dotazů~\cite{rdbs-optimalizace}. Pokud chceme do RDBS ukládat záznamy obsahující uživatele, musí mít každý záznam stejnou strukturu. Takže uživatel musí obsahovat všechny povinné atributy, jako jsou jméno a příjmení, a dodržet jejich předem stanovený datový typ a velikost, například počet číslic v telefonním čísle. Pokud by záznam obsahoval nějaké atributy navíc, například informaci o tom, zda je uživatel nemocný, nebo by jejich datový typ neodpovídal očekávanému, je zapotřebí upravit i schéma tabulky, do které záznam vkládáme, a také záznamy, které se již v této tabulce nachází.
	
	Na druhou stranu, KDBS mohou mít pro každý klíč různé hodnoty, např. textové řetězce, seznamy řetězců a čísel nebo JSON dokumenty. Tato vlastnost nabízí KDBS flexibilitu a možnost změnit datové typy hodnot bez zásahu do struktury DBS~\cite{schemaless-vs-schema-2}. KDBS se často používají pro správu relací ve webových aplikacích. Dobře uchovávají informace o stavu pro všechny uživatele aplikace. KDBS lze použít také v online hrách pro více hráčů, kde spravují relace jednotlivých hráčů. Osvědčují se při správě nákupních košíků pro online nákupy až do doby platby. Pro platební transakce a účtování příjmů vyhovují lépe RDBS~\cite{kdbs-memory}.
	
	Do KDBS můžeme pro klíče jako ID uživatele ukládat hodnoty v podobě JSON dokumentů reprezentujících záznamy uživatelů. Tyto dokumenty mohou reprezentovat uživatele, kteří jsou definováni odlišným způsobem a mají různý počet a datový typ atributů. Dále KDBS často dosahují horizontální škálovatelnosti a poskytují automatickou distribuci napříč servery (viz kapitola~\ref{scaling-dbs}). V KDBS bývá ukládání rychlé a jednoduché, ale dochází k vyšší spotřebě místa, obzvlášť pokud nejsou data komprimována. V KDBS se objevuje redundance, při které hrozí nekonzistence dat. Nepoužívá se dekompozice schématu, což rovněž zvyšuje objem dat. Naopak u RDBS bude uložení efektivnější díky normalizaci~\cite{normalizace} a kompresním technikám, ale režijní náklady na indexy a metadata~\cite{metadata} zvyšují celkovou velikost dat.
	
	Databáze se schématem~\cite{schemaless-vs-schema} vyžadují definici schématu databáze před tím, než jsou data uložena. To znamená, že musíme předem definovat schéma včetně datových typů, a poté můžeme data vložit do DBS. Na druhou stranu databáze bez schématu (schema-on-read, schema-less) umožňují ukládat data bez předchozí definice datového schématu. Schéma je definováno až v okamžiku, kdy data čteme z DBS. To umožňuje pružnější přístup k ukládání a zpracování dat, za cenu komplikovanějšího dotazování. Může to vést k menší kontrole nad strukturou dat a zvyšuje se pravděpodobnost nekonzistence dat kvůli vysoké redundanci. Nicméně KDBS a obecně NoSQL DBS často umožňují definovat schéma, pokud je to potřeba.
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.65]{Data/db-engine-trend-dbs.PNG}
		\caption{Graf hodnot popularity RDBS Oracle a KDBS Redis~\cite{dbranking-trend-by-dbs}\label{graf-dbranking-trend-dbs}}
	\end{figure}
	
	Výkon a nedostatečná standardizace omezovaly KDBS pouze na specializovaná využití, ale díky rychlému přechodu na cloud computing, dochází v posledních letech k nárůstu popularity NoSQL databázových systémů, zatímco popularita RDBS je víceméně stejná~\cite{dbranking-trend-by-model}. Dle výzkumu z roku 2019~\cite{scalegrid-sql-vs-nosql} byly RDBS využívány v 60,48~\% případů napříč všemi databázovými systémy, zatímco NoSQL DBS pak zastávaly zbylých 39,52~\%. Často se však pro využití výhod různých druhů DBS využívá kombinace relačních a NoSQL databází. Tato kombinace je proto využívána v 75,6~\% případů. Samostatně využívané RDBS poté zabírají 16,6~\% a NoSQL DBS 9,8~\%.
	
	Webová stránka DB-Engines~\cite{dbranking-web-index} porovnává DBS na základě popularity. Bodové skóre popularity je spočítáno na základě počtu zmínek na webových stránkách, frekvenci diskuzí na technických fórech, pracovních nabídek a poptávek, relevance DBS na sociálních sítích, počtu profilů na profesních sociálních sítích zmiňujících daný DBS a obecného zájmu o DBS~\cite{dbranking-ranking-definition}. Při sledování trendu DBS od roku 2013 do současnosti~\cite{dbranking-trend-by-dbs} (viz obrázek~\ref{graf-dbranking-trend-dbs}) dochází k výraznému nárůstu hodnocení popularity NoSQL DBS, konkrétně KDBS Redis~\cite{redis} zaznamenala nárůst od roku 2013 z 25,9 bodů na 156,4 bodů, došlo tedy k nárůstu popularity o 502,7~\%. Pro RDBS Oracle~\cite{oracle-index} došlo naopak k poklesu popularity z 1559,3 bodů na 1234,3 bodů, pokles činí 20,9~\%. Trend změny hodnot popularity~\cite{dbranking-trend-by-model} (viz obrázek~\ref{graf-dbranking-trend-model}) pro RDBS obecně od roku 2013 se příliš nemění a dochází k poklesu v maximálně jednotkách bodů každý měsíc, KDBS naopak znatelně stoupaly se svým hodnocením do konce roku 2022 a aktuálně dochází k poklesu popularity v řádu několika jednotek bodů každý měsíc.
	
	Například databázový systém Redis je v současnosti jedním z deseti nejlépe hodnocených databázových systémů napříč relačními i NoSQL databázovými systémy~\cite{db-engineers-ranking}. V žebříčku porovnání téměř 70 pouze KDBS~\cite{db-engineers-ranking-kdbs}, je Redis na prvním místě, za ním následují Amazon DynamoDB~\cite{dynamodb}, společně s Microsoft Azure Cosmos DB~\cite{azure-cosmos-db} a Memcached~\cite{memcached}.

	\begin{figure}
		\centering
		\includegraphics[scale=0.65]{Data/db-engine-trend-model.PNG}
		\caption{Graf změn hodnot popularity RDBS a KDBS~\cite{dbranking-trend-by-model}\label{graf-dbranking-trend-model}}
	\end{figure}
	
	Cílem práce je prostudovat a podrobně popsat problematiku KDBS. Práce se zaměří na vysvětlení tohoto konceptu a identifikaci klíčových rozdílů mezi jednotlivými KDBS. Jednou z hlavních úloh práce je zmínit a detailně popsat některé z nejznámějších a nejčastěji využívaných databázových systémů v tomto odvětví. Tyto DBS budou vzájemně porovnány s důrazem na jejich vlastnosti, výhody a nevýhody. Dalším úkolem práce je příprava a zprovoznění testovacího prostředí, které umožní měření propustnosti a odezvy na dotazy vybraných KDBS. Návrh a implementace testovacího prostředí zahrnuje konfiguraci prostředí a zprovoznění instancí databázových systémů, ať už lokálně nebo v cloudovém prostředí. Následně budou vybrané DBS podrobeny testování a budou měřeny jejich propustnosti a latence v reálném provozu. Naměřené hodnoty budou prezentovány a analyzovány s cílem porovnat chování jednotlivých DBS v různých scénářích. Konečné výsledky budou porovnány, což umožní srovnání jednotlivých DBS při dotazování a manipulaci s daty.
	
	Struktura práce je následující. První část práce (kapitola~\ref{chapter:no-sql-ky-sys}) se zaměřuje na detailní představení několika klíčových KDBS (např. Redis, Riak KV, Aerospike). Každý z těchto DBS je popsán, a to včetně analýzy jejich charakteristických vlastností. V závěru této části je provedeno srovnání jednotlivých DBS na základě jejich vlastností, například škálovatelnosti, dotazovacích jazyků a odezvy.
	
	Kapitola \ref{chapter:3-test_environment} obsahuje popis testovacích prostředí databázových systémů. V kapitole jsou uvedena dvě existující testovací prostředí TPC~\cite{tpc} a YCSB~\cite{ycsb}. Testovací prostředí TPC je využíváno především pro relační databázové systémy, zatímco prostředí YCSB je připraveno a vyvíjeno zejména pro NoSQL DBS.
	
	Kapitola \ref{chapter:4-test_results} je věnována testování a vyhodnocení výsledků čtyř vybraných KDBS (Redis~\cite{redis}, Riak KV~\cite{riak}, Aerospike~\cite{aerospike} a Memcached~\cite{memcached}). Tyto DBS byly vybrány z důvodu své relevance podle internetových žebříčků~\cite{db-engineers-ranking, predictiveanalyticstoday}. Kapitola popisuje stroj, na kterém se KDBS testovaly, a potřebnou přípravu zvoleného testovacího prostředí YCSB a databází v Dockeru~\cite{docker}. Konkrétně se zde popisují konfigurace jednotlivých testů, kroky pro spuštění testů a samotné testování. Kapitola je zakončena prezentací výsledků naměřených hodnot při testování a porovnáním výsledků jednotlivých KDBS. 
	
	V závěru práce, v kapitole \ref{chapter:5-diploma_results}, jsou vyhodnoceny výsledky srovnání KDBS. Součástí kapitoly je zhodnocení samotné práce.
	
	\chapter{NoSQL, Key-value databázové systémy\label{chapter:no-sql-ky-sys}}
	
	NoSQL (Not Only SQL) databázové systémy~\cite{nosql} představují třídu databázových systémů, které často ukládají a spravují data odlišně oproti relačním databázím. Tyto systémy byly vyvinuty jako odpověď na rostoucí potřeby moderních aplikací, které vyžadují vysokou škálovatelnost, flexibilitu a rychlý přístup k datům. Hlavním rysem NoSQL DBS je jejich schopnost efektivně zpracovávat velké objemy různorodých dat.
	
	Škálovatelnost~\cite{scalability}\label{scaling-dbs} je schopnost systému přizpůsobit se zvýšené zátěži nebo rostoucímu objemu dat a zachovat požadovanou úroveň výkonu a dostupnosti. Existují různé druhy škálovatelnosti DBS. Horizontální škálovatelnost zahrnuje rozložení zátěže a zvýšení celkové kapacity přidáním dalších uzlů nebo serverů k distribuovanému systému. Vertikální škálovatelnost zlepšuje výkon jednotlivých uzlů nebo serverů zvětšením jejich výpočetní nebo paměťové kapacity. Lineární škálovatelnost je ideální situace, kdy se se zvýšením zdrojů (buď horizontálně nebo vertikálně) zvyšuje výkon systému lineárně.
	
	Databázové systémy lze klasifikovat do několika kategorií na základě jejich datového modelu, způsobu ukládání dat a způsobu přístupu k datům. Hlavní klasifikace zahrnují RDBS a NoSQL DBS. NoSQL DBS se dále dělí do několika podkategorií, mezi které patří:
	
	\begin{itemize}
		\item Key-value databázové systémy
		\item Dokumentové databázové systémy
		\item Sloupcové databázové systémy
		\item Grafové databázové systémy
	\end{itemize}
	
	Určité vlastnosti DBS se dají popsat pomocí pojmů ACID a BASE~\cite{acid-vs-base}. Oba tyto pojmy si vysvětlíme. ACID je soubor čtyř vlastností, které zajišťují spolehlivost a integritu transakcí především v tradičních relačních databázích. Tyto vlastnosti jsou klíčové pro aplikace, které vyžadují vysokou úroveň konzistence~\cite{integrita}, jako jsou například bankovní systémy a systémy pro správu objednávek.
	
	\begin{itemize}
		\item Atomicita (A): Transakce je nedělitelná jednotka řady dotazů; buď se provede celá, nebo žádná její část.
		\item Konzistence (C): Transakce převádí databázi z jednoho konzistentního stavu do druhého.
		\item Izolace (I): Současně běžící transakce se navzájem neovlivňují.
		\item Trvanlivost (D): Po dokončení transakce jsou změny trvalé, i když dojde k výpadku systému.
	\end{itemize}
	
	BASE je alternativní přístup k ACID, který je častěji používán v NoSQL databázích, zejména v distribuovaných systémech. BASE přístup je často preferován pro systémy, které vyžadují vysokou dostupnost a rychlost, jako jsou sociální sítě a webové aplikace, kde je akceptovatelné dočasné zpoždění v konzistenci dat.
	
	\begin{itemize}
		\item Basically Available (B): Systém garantuje maximální dostupnost čtení a zápisů s použitím všech uzlů sítě, ale čtení nemusí být konzistentní (nemusí vracet poslední zápis).
		\item Soft state (S): Stav systému se může měnit v čase, i bez vstupu, kvůli eventuální konzistenci.
		\item Eventual consistency (E): Pokud provedeme nějaké zápisy a systém bude pracovat dostatečně dlouho (bez zápisu), dojde ke konvergenci dat (další čtení budou vracet stejnou hodnotu posledního zápisu)~\cite{base-vsb}.
	\end{itemize}
	
	V oblasti distribuovaných systémů se objevuje i CAP teorém~\cite{cap-theorem}, který formuluje omezení, jež se vyskytuje při návrhu distribuovaných databázových systémů. CAP teorém tvrdí, že v rámci distribuovaného systému nelze zároveň zaručit všechny tři vlastnosti (Konzistence, Dostupnost, Tolerance rozdělení) zcela současně. To znamená, že při návrhu distribuovaného systému je třeba se rozhodnout, na které dvě vlastnosti se bude kladen důraz, zatímco třetí vlastnost bude muset být omezena. CAP teorém poskytuje důležitý rámec pro rozhodování při návrhu a provozu distribuovaných systémů, kde je klíčové vyvážit požadavky na konzistenci dat, jejich dostupnost a schopnost systému pracovat v prostředí s možností rozdělení sítě.
	
	\begin{itemize}
		\item Konzistence (C): Všichni uživatelé vidí stejná data ve stejném čase, bez ohledu na to, kde jsou v distribuovaném systému požadavky zpracovávány. Konzistence je tedy zajištěna okamžitě po provedení aktualizace dat.
		\item Dostupnost (A): Každý požadavek na čtení nebo zápis v distribuovaném systému obdrží odpověď - buď úspěšnou odpověď s daty, nebo chybovou hlášku, pokud došlo k chybě. Dostupnost znamená, že systém je schopen odpovídat na požadavky i za přítomnosti poruch.
		\item Odolnost proti rozdělení, tolerance rozdělení (P): Systém stále funguje i v případě, že mezi jednotlivými uzly distribuovaného systému dojde k rozdělení nebo ztrátě komunikace (partition). Tato vlastnost je klíčová pro robustnost distribuovaných systémů, které pracují v prostředích s možností výpadků sítě.
	\end{itemize}
	
	\begin{itemize}
		\item Konzistence a Tolerance rozdělení (CP): Zajišťuje se konzistence a odolnost proti rozdělení, ale to může vést k dočasné nedostupnosti (např. v případě rozdělení sítě).
		\item  Dostupnost a Tolerance rozdělení (AP): Zajišťuje se dostupnost a odolnost proti rozdělení, ale může docházet ke krátkodobé nekonzistenci mezi replikovanými daty.
		\item Konzistence a Dostupnost (CA): Tato kombinace není možná podle CAP teorému, protože nelze zaručit dostupnost při plné konzistenci a bez tolerance rozdělení.
	\end{itemize}
	
	\section{Key-value databázové systémy}
	
	KDBS~\cite{kdbs-oracle, kdbs-redis} jsou typem databázového systému, který slouží pro ukládání dat ve formě jednoduchých párování klíč-hodnota bez pevně definovaného schématu dat. Klíč slouží jako unikátní identifikátor, který umožňuje rychlé vyhledávání a přístup k datům (hodnotám) i při jejich velkém objemu. Každá hodnota v databázi je uložena v páru se svým klíčem. Tyto databáze jsou často preferované pro svou schopnost rychle a efektivně ukládat a získávat různorodá data~\cite{kdbs-quick-fast}, což je zvláště důležité pro aplikace, které potřebují vysoký výkon a horizontální škálovatelnost při velké zátěži.
	
	Důležitým rysem těchto DBS je také jejich horizontální škálovatelnost. Mohou zpracovávat velké objemy dat a udržovat vysoký výkon i při zvyšujícím se počtu uživatelů nebo objemu dat. Některé KDBS nabízejí distribuované ukládání dat, což umožňuje rozložení dat mezi různé servery a zvýšení dostupnosti celého systému. RDBS tradičně spoléhají na vertikální škálování, ale i přesto mohou být distribuované.
	
	Pro uživatele bývá klíčovým faktorem také jednoduchost použití. KDBS poskytují jednoduché rozhraní pro práci s daty, které zahrnuje základní operace jako vložení (PUT), odstranění (DEL) a vyhledávání dat pomocí klíče (GET). Tato jednoduchost usnadňuje integraci KDBS do různých aplikací a nezvyšují nároky na vývojáře. Nicméně pro práci s daty existují pro vybrané KDBS i vlastní SQL jazyky, které vyžadují obeznámení se s danou technologií (např. RediSQL~\cite{redisql} pro Redis~\cite{redis} nebo PartiQL~\cite{partiql} pro Amazon DynamoDB~\cite{dynamodb}).
	
	Vzhledem k těmto vlastnostem jsou KDBS vhodné pro širokou škálu aplikací, včetně webových aplikací, analytických systémů, cache pamětí a dalších~\cite{kdbs-memory, common-use-kdbs}. Jsou ideální pro situace, kde je potřeba rychle a efektivně ukládat a získávat data a zároveň udržovat vysoký výkon a škálovatelnost systému.
	
	Jelikož KDBS jsou primárně určeny pro distribuované nasazení, nyní popíšeme tento pojem. Distribuovaný databázový systém~\cite{ddbs} je typ databázového systému, který ukládá data na několik počítačů (neboli uzlů) v rámci sítě. Tento přístup umožňuje flexibilní zpracování velkých objemů dat a zlepšuje odolnost systému vůči výpadkům jednotlivých uzlů. Pokud je konkrétní uzel nedostupný kvůli výpadku nebo zvýšené odezvě způsobené přetížením, můžeme jednoduše pokračovat v komunikaci s jiným uzlem, i když je možná vzdálenější. Distribuovaná architektura umožňuje systému růst s rostoucím objemem dat a zároveň snižuje riziko selhání komunikace, což zvyšuje celkovou spolehlivost a dostupnost systému. Dostupnost~\cite{availability} znamená, že data nebo jiné zařízení jsou k dispozici v daném okamžiku. Vyjadřuje se v procentech dostupného času. Dostupnost systému je možné zvýšit například pokrytím rozsáhlejších geografických oblastí vhodným rozmístěním uzlů a přidáním nových uzlů do systému. Tím dosáhneme i kratší odezvy díky možnosti komunikace s uzly blíže uživatelům.
	
	V distribuovaných databázových systémech je uzel (node) jednotkou, která zpracovává část dat a provádí operace nad nimi. Každý uzel může mít svůj vlastní výpočetní výkon, paměť a úložiště. Uzly spolupracují a komunikují mezi sebou pro správu a dotazování dat. Uzel může být fyzický server nebo virtuální stroj, který běží na fyzickém hardware a poskytuje databázové služby. Shluk uzlů (cluster of nodes) je skupina databázových uzlů. Každý shluk může obsahovat primární a replikované uzly, které sdílejí zátěž a zároveň poskytují redundanci dat pro zajištění vyšší dostupnosti. Shluk uzlů může mít různé vlastnosti, jako je počet uzlů, topologie sítě, algoritmy rozhodování a replikace dat.
	
	Distribuované NoSQL DBS se JOIN operacím~\cite{join} často vyhýbají, aby se zachoval výkon a škálovatelnost. Místo toho se používají následující strategie. Jednou ze strategií je denormalizace, u které jsou data často duplikována napříč různými kolekcemi nebo tabulkami, aby se eliminovala nutnost použit operaci spojení JOIN. Například informace o uživateli a jeho příspěvcích mohou být vloženy do jednoho dokumentu, pokud jsou často dotazovány společně. Případně může být logika operace na straně klienta. Místo provádění JOIN operací uvnitř databázových systémem může aplikace načíst související data z více uzlů a kombinovat je v aplikační vrstvě. Případně lze dotazy přímo směřovat na relevantní uzly. Některé NoSQL systémy, jako Cassandra~\cite{cassandra}, umožňují směrování dotazů na specifické uzly, které obsahují relevantní data, čímž se snižuje potřeba JOIN operací.
	
	V současné době existuje celá řada KDBS, od malých open-source projektů po velké komerční cloudové služby. Různé systémy disponují odlišnými vlastnostmi, jako je rychlost zpracování dat, škálovatelnost, uživatelská přívětivost skrze jednoduchou konfiguraci DBS a rozhraní pro práci s daty atd. Dle průzkumu~\cite{predictiveanalyticstoday,g2,db-engineers-ranking} bylo vybráno~9 významných KDBS. Cílem je představit tyto KDBS, popsat jejich klíčové vlastnosti a provést jejich porovnání (viz tabulka~\ref{tab_kvdb_compare}). Z uvedených KDBS se následně provede konečný výběr databázových systémů pro testování a porovnání pro dané vytížení.
	
	\section{Dokumentové databázové systémy}
	
	Dokumentové DBS~\cite{nosql, dokument-dbs} jsou typem NoSQL DBS, které ukládají data ve formě dokumentů, typicky ve formátech jako JSON~\cite{json}, BSON~\cite{bson} nebo XML~\cite{xml}. Tento model umožňuje flexibilní schéma, což znamená, že každé pole (field) v dokumentu může mít různé typy dat a strukturu. Hlavní výhoda dokumentových DBS spočívá v jejich schopnosti snadno a rychle měnit schéma dat, což je ideální pro aplikace, které vyžadují časté aktualizace a rozšiřování. Dokumentové DBS, jako jsou MongoDB~\cite{mongodb} nebo CouchDB~\cite{couchdb}, jsou využívány v široké škále aplikací, včetně správy obsahu, katalogů a uživatelských profilů, kde je potřeba uchovávat složitější struktury dat.
	
	Klíčovým rozdílem mezi KDBS a dokumentovými DBS je jejich schéma dat. KDBS jsou navrženy pro jednoduchost a rychlost přístupu k datům pomocí klíče, což je ideální pro aplikace, kde je potřeba rychlý a predikovatelný přístup k datům. Na druhé straně, dokumentové databáze poskytují flexibilitu v ukládání a dotazování na složité datové struktury, což je vhodné pro aplikace vyžadující práci s variabilními a často se měnícími schématem dat. Zatímco KDBS excelují v jednoduchých operacích s vysokým výkonem, dokumentové DBS nabízejí bohaté možnosti dotazování a větší flexibilitu při práci s komplexními daty.
	
	\section{Sloupcové databázové systémy}
	
	Pokud při dotazování pracujeme pouze s malým počtem atributů, tak lze efektivně využít sloupcového uložení dat. Sloupcové DBS (wide-column store)~\cite{nosql} ukládají data v tabulkách, kde jsou data seskupena podle sloupců místo tradičních řádků. Každý sloupec může obsahovat různé typy dat a jsou organizovány tak, aby bylo možné rychle provádět dotazy (hlavně agregace při sekvenčním průchodu tabulkou) na velká množství dat s malým počtem atributů. Sloupcové DBS, jako jsou Apache Cassandra~\cite{cassandra} a HBase~\cite{hbase}, jsou obzvláště efektivní při zpracování analytických dotazů, protože umožňují rychlé čtení velkého množství dat najednou. Sloupcové uložení dat může dosahovat vyššího komprimačního poměru (např. pomocí komprimace RLE~\cite{rle}), obzvlášť při často opakujících se hodnotách~\cite{base-vsb}.
	
	\section{Grafové databázové systémy}
	
	Grafové DBS~\cite{nosql} jsou specializovaným typem NoSQL DBS, které jsou optimalizovány pro ukládání a navigaci v grafech (datových strukturách, které jsou představovány uzly, hranami a vlastnostmi). Příkladem grafových dat jsou sociální sítě, doporučovací systémy nebo řízení vztahů se zákazníky (CRM~\cite{crm}). Grafové DBS, jako jsou Neo4j~\cite{neo4j} a Amazon Neptune~\cite{amazon-neptune}, umožňují efektivní dotazování na vztahy mezi uzly, což může být náročné v tradičních relačních databázích. Nicméně i dnešní RDBS již mají vlastní rozšíření pro ukládání a dotazování grafů. Hlavní předností grafových databází je jejich schopnost modelovat a dotazovat se na složité vztahy.
	
	\section{Významné Key-value databázové systémy}
	
	\subsection{Amazon DynamoDB}
	
	Amazon DynamoDB~\cite{dynamodb} je v současné době druhá nejpopulárnější KDBS~\cite{dynamodb-dbengines-rank2}. Jedná se o cloudový systém bez lokálních serverů (známý též jako serverless cloud system), který nabízí nízkou odezvu a automatickou škálovatelnost~\cite{dynamodb-autoscaling}. Těchto vlastností je dosaženo díky správě cloudu ze strany provozovatele a monitoringu běhu databáze. Databáze v cloudu se používá pro popis architektury, kde se vývojáři především soustředí na vývoj softwaru (aplikace) a provozovatelé cloudu se starají o provoz, škálování a správu infrastruktury bez nutnosti spravovat samostatné servery. Amazon DynamoDB se využívá v oblastech jako aplikace sociálních médií, real-time analýza, bez serverové aplikace a herní průmysl~\cite{amazon-usecases}. DynamoDB je plně a automaticky spravovatelná, multi-master~\cite{multicluster} databáze zaměřená na využití horizontální škálovatelnosti. Multi-master databáze~\cite{postgres-multimaster-replication} je typ distribuované databáze umožňující práci s různými uzlů současně. Každý uzel má stejná oprávnění k provádění zápisů, které jsou synchronizovány mezi všemi uzly. Tímto způsobem může být zajištěna vyšší dostupnost a odolnost systému proti výpadkům. Pokud jeden uzel selže, ostatní uzly mohou stále zpracovávat zápisy. DynamoDB podporuje různé režimy konzistence dat (ACID) a umožňuje zápis na více replik v rámci své infrastruktury. Tak jako každý běžný KDBS má unikátní primární klíče, které umožňují identifikaci jednotlivých záznamů v tabulkách, tak DynamoDB má i indexy~\cite{dynamodb-secondary-index} pro zlepšení odezvy dotazů a flexibility. Klíč slouží jako vstup do hashovací funkce a výsledná hashovací hodnota určuje fyzickou pozici uloženého záznamu. DynamoDB poskytuje silnou konzistenci při čtení hodnot od poslední aktualizace. Silná konzistence~\cite{strong-consistency} v databázích představuje schopnost poskytovat aktuální a přesné hodnoty dat v rámci operací čtení. To znamená, že jakmile jsou data aktualizována nebo zapsána do databáze, jakékoli následné čtení těchto dat vrátí nejnovější hodnotu. Atomické čítače~\cite{atomic-counter} umožňují automatické změny hodnot číselných atributů. To zajišťuje konzistenci a spolehlivost čtecích operací v databázových systémech tím, že garantuje, že data vrácená z čtení jsou platná v daném okamžiku a nebyla ovlivněna současnými změnami. Pro expirované záznamy v tabulkách využívá tzv. TTL (Time To Live)~\cite{ttl} k označení doby, po kterou má záznam zůstat platný v databázi. Archivace dat je umožněna díky full backupu~\cite{full-backup}. Což znamená, že kompletní kopie všech dat uložených v databázi je vytvořena v určeném časovém okamžiku, což umožňuje obnovu dat do jejich stavu v okamžiku vytvoření zálohy. Amazon DynamoDB rovněž nabízí VPC~\cite{vpc} pro soukromou komunikaci přes privátní síťové prostředí v rámci AWS cloudu.
	
	Databázový systém disponuje konzolovým DynamoDB API~\cite{api-dynamodb} pro správu databáze a práci s daty, ale nabízí také možnost využití jazyka PartiQL~\cite{partiql}, který je vhodný pro SQL dotazy~\cite{what-is-sql} na databázích bez schématu. DynamoDB API je rozděleno do čtyř hlavních částí. První část, kontrolní plán~\cite{control-plan-dynamodb, api-dynamodb}, zahrnuje funkce spojené s vytvářením, úpravami, mazáním a získáním jmen všech tabulek. Dále umožňuje výpis podrobných specifikací dané tabulky, jako jsou primární klíče, indexy a nastavení propustnosti. Druhá část API, datový plán~\cite{api-dynamodb}, který poskytuje CRUD operace pro data v dané tabulce. S daty lze pracovat buď jednotlivě po záznamech, nebo pomocí Batch funkcí, které umožňují provést stejnou operaci nad desítkami záznamů najednou a dosáhnout tak vyšší propustnosti, než při volání stejných funkcí pro jednotlivé záznamy opakovaně. Také je možné provést Scan~\cite{scan-dynamo} pro získání všech záznamů dané tabulky nebo indexu, případně Query~\cite{query-dynamo} pro získání hledané části dat (viz výpis příkladů níže). Třetí částí API je DynamoDB Streams pro práci s časovými sekvencemi a práci s logy za posledních 24 hodin. Stream API poskytuje funkce pro výpis všech streamů, konkrétní popis daného streamu, získání iterátoru pro daný stream a nakonec získání jednoho záznamu z daného streamu. Čtvrtou částí API jsou ACID transakce, které jsou rozděleny do dvou sekcí. První sekce je určena pro hromadné vkládání, úpravu a mazání záznamů a druhá sekce slouží pro hromadné získání záznamů.
	
	Příklady příkazů bodového dotazu (get-item) a sekvenčního průchodu všech položek na základě indexu (query) prostřednictvím DynamoDB API:
	
	\begin{itemize}
		\item aws dynamodb get-item \\
		--table-name Users	\\
		--key '\{"UserID": \{"S": "user123"\}\}'
		\item aws dynamodb query \\
		--table-name Users \\
		--index-name EmailIndex \\
		--key-condition-expression "Email = :email" \\
		--expression-attribute-values '\{":email":\{"S":"user123@myemail.com"\}\}'~\cite{query-dynamo, scan-dynamo}
	\end{itemize}
	
	První příkaz načte položku z tabulky "Users"~na základě primárního klíče "UserID". Vlastnost "--table-name Users"~určuje název tabulky, ze které chcete načítat data. A "--key '\{"UserID": \{"S":~"user123"\}\}'"~specifikuje primární klíč položky, kterou chcete načíst. V tomto případě je primární klíč pojmenován "UserID", který je datového typu řetězce "S"~s hodnotou "user123". 
	
	Druhý příkaz načte všechny položky z tabulky "Users"~na základě sekundárního indexu "EmailIndex", kde "Email"~je "user123@myemail.com". Název sekundárního indexu který chcete použít pro dotaz specifikuje vlastnost "--index-name EmailIndex". Vlastnost "--key-condition-expression "Email~=~:email":"~definuje podmínku pro dotaz, kde "Email"~musí být rovno ":email". Nakonec vlastnost "--expression-attribute-values '\{":email":\{"S":"user123@myemail.com"\}\}'"~poskytuje hodnotu atributu ":email", který je datového typu řetězce s hodnotou "user123@myemail.com".
	
	\subsection{Oracle NoSQL Database}
	
	Oracle NoSQL Database~\cite{oraclenosqldb} je databázová cloud služba vhodná pro práci s velkými objemy dat a nízkou odezvou. Služba je postavena na Oracle Berkeley DB~\cite{berkeleydb} (viz kapitola~\ref{lab-oracle-berkleydb}). Databáze je plně spravovatelná a škáluje horizontálně. Tato KDBS složí i jako úložiště pro dokumenty a data s pevně daným schématem. Databázový systém je vyvíjen společností Oracle, proto může být pro vývojáře snadné začít tuto službu využívat a soustředit se pouze na vývoj aplikací. Není pak potřeba se zabývat správou základní infrastruktury databáze, softwaru, zabezpečení atp. Jedná se o Single Master, Multi Replica grafový systém~\cite{oracle-singlemaster-multireplica}, což znamená, že má jeden hlavní uzel (Single Master), který je zodpovědný za zápis dat a řízení replikace, a více replik (Multi Replica), které obsahují kopie dat a jsou synchronizovány s hlavním uzlem. Pokud dojde k chybě na hlavním uzlu, je hlavní uzel automaticky nahrazen jednou z replik. Pro ukládání velkých dat využívá systém konfigurovatelné Storage uzly~\cite{oracle-storage-node}. Pro udržení konzistence jsou Storage uzly replikovány. Sdílený systém, uniformně alokuje data okolo ostatních částí skupin. DBS obsahuje i SQL jazyk pro import, export a přenos dat mezi Oracle NoSQL databázemi. Tento jazyk se nazývá SQL Shell~\cite{oracle-sql-shell}. Mimo jiné je zde podpora i pro Failover~\cite{failover}, SwitchOver~\cite{switchover}, Bulk Get API~\cite{oracle-bulkapi}, Off Heap Cache~\cite{offheapcache} a podpora Big Data SQL~\cite{oracle-big-data-sql}.
	
	Restové API je rozděleno do pěti částí. První částí je správa indexů~\cite{index}, pro vytváření a mazání vlastních indexů. Tato část API také umožňuje zobrazit všechny indexy, které jsou pro danou tabulku vytvořeny a společně s detailním popisem každého indexu. Druhá část API se věnuje dotazům, umožňuje tedy syntaktickou kontrolu daného SQL dotazu, před připravení a spuštění dotazu. Třetí část je zaměřena na správu záznamů, obsahuje tedy CRUD funkce pro jednotlivé záznamy. Tato část ale neobsahuje funkci pro aktualizaci existujícího záznamu a ani neumožňuje správu více než jednoho záznamu najednou, pro úpravu je tedy nutno provést funkci odstranění záznamu a vložení nového. Čtvrtá část je zaměřena správě tabulek, obsahuje možnost vytvoření, upravování, a mazání tabulek. Tato část také umožňuje výpis všech tabulek, informace o dané tabulce a využívání dané tabulky. Poslední část API se věnuje správě pracovních požadavků, lze zde zobrazit stav jednotlivých požadavků, mazat požadavky, získat chyby či log daného požadavku a seznam všech požadavků.
		
	\subsection{Redis} \label{lab-redis}
	
	Redis~\cite{redis} je paměťové (in-memory) úložiště pro různorodá data, využívané jako KDBS nebo cache. Jedním z častých případů využití DBS Redis, je pro práci s daty, kde klíče mají podobu hashe a hodnoty mohou být JSON dokumenty. Pro persistenci dat můžeme ukládání dat na disk provádět po nastavitelných pravidelných intervalech, nebo je možné data logovat vždy při vykonávání operací. Pokud nemáme zájem o persistenci dat, je možné ukládání dat úplně vypnout a datové úložiště využít čistě jako paměťové. Úložiště škáluje horizontálně. Redis mimo JSON dokumenty podporuje pro hodnoty i datové struktury jako primitivní textové řetězce, hashe, seznamy, množiny, bitmapy, hyperloglog a geospatial data. Nad datovými typy Redis umožňuje rychlé operace, jako je rozšíření řetězců, přidání prvků na začátek a konec seznamů, atd. Datové úložiště Redis také poskytuje seřazené množiny (sorted sets) pro vytváření indexů dle ID nebo jiného číselného atributu. Pro správu indexů lze také využít Hash Mapy (hashes), množiny (sets) a seznamy (lists). Redis pro implementaci indexů nepoužívá tradiční stromové struktury (jako B-stromy nebo AVL stromy). Redis hashing umožňuje převedení klíčů na hash, nicméně klíče mohou být i jednoduché řetězce bez hashe. Redis Keyspace notifikace~\cite{redis-keyspace-not} dovoluje klientům odebírat zprávy z kanálů dle vzoru Publisher-Subscriber. Pro práci s dotazy na souřadnice a geometrii je možné využívat Geo API~\cite{redis-geospatial}. Redis umožňuje provádět transakce s případnou konzistencí, volat Lua skripty a nastavovat různé úrovně TTL pro záznamy. Struktura pro ukládání dat je single-rooted replikovaný strom~\cite{tree-replic}. Redis má vlastní API pro práci s daty pro populární programovací jazyky jako C, Python, Java a JavaScript.
	
	S Redis databází lze pracovat například pomocí konzolového rozhraní, toto CLI~\cite{rediscli} poskytuje řadu krátkých příkazů pro práci s daty. Vždy potřebujeme specifikovat klíč, se kterým chceme v databázi pracovat. Pomocí příkazu SET a DEL vkládáme nebo mažeme jednotlivé hodnoty pro zvolený klíč. Příkazem GET získáme hodnoty pro daný klíč, případně můžeme zjistit, zda již existuje záznam pro daný klíč příkazem EXISTS. Pokud vyžadujeme práci se seznamy, tak můžeme pro daný klíč zleva i zprava vkládat hodnoty zřetězené v seznamu díky příkazům LPUSH a RPUSH. Obdobně odebíráme hodnoty ze seznamu pomocí LPOP a RPOP, příkazem LRANGE vypíšeme hodnoty ze seznamu a příkazem LLEN zjistíme počet jeho prvků. Místo jednoduchých seznamů je možno pracovat i s množinami pomocí příkazů SADD, SREM, SISMEMBER a obdobně. Množiny mohou být i seřazené a pro ně se využívají příkazy jako ZADD. Pro práci se záznamy strukturovanými jako kolekce párů atribut-hodnota se využívá datový typ Hash, umožňuje nám pro daný klíč uložit záznam obsahující názvy atributů a jednotlivé hodnoty pro ně. Opět se zde využívají příkazy jako HSET a HGETALL pro nastavení a získání daného záznamu, případně HGET pro získání hodnoty daného atributu pro záznam na zadaném klíči. API obsahuje také příkazy pro ostatní datové typy, jako jsou bitmapy, geografické prostory, HyperLogLog a další.
	
	\subsection{Aerospike} \label{lab-aerospike}
	
	Aerospike~\cite{aerospike} je KDBS využívající Hybrid Memory architekturu~\cite{hybmem-arch}, která může způsobit zvýšení propustnosti. Hybrid Memory architektura od Aerospike je implementována tak, že index je čistě paměťový (in-memory) a klíč-hodnota páry jsou uloženy perzistentně na SSD disku~\cite{ssd-avast} a čtou se přímo z něj. Díky tomu, že je Aerospike jako KDBS bez schématu, je možné definovat Sets a Bins~\cite{aerospike-datamodel} za běhu pro flexibilitu aplikací. Set (sada) v Aerospike je logická skupina záznamů uvnitř konkrétního jmenného prostoru (namespace). Sety umožňují organizovat a kategorizovat záznamy uvnitř jednoho jmenného prostoru. Bin ("přihrádka") v Aerospike je základní jednotka pro ukládání dat uvnitř záznamu. Každý záznam v Aerospike může obsahovat jeden nebo více binů, kde každý bin má svůj název a hodnotu. Databáze škáluje lineárně a poskytuje silnou konzistenci a korektnost. Umožňuje real-time analýzu~\cite{aerospike-rtanalysis} pro rozhodování a dynamickou optimalizaci pro využívání zdrojů dat, proto je databáze využitelná pro rozsáhlé DBS s vysokým zatížením. Aerospike tvrdí, že poskytuje server-side clustering~\cite{aerospike-clustering} a bezpečnost na transportní vrstvě. Databáze umožňuje customer deployment~\cite{aerospike-deployment} s nepřetržitým během. V praxi se Aerospike díky svým vlastnostem využívá například pro bankovní systémy, telekomunikace, reklamní technologie a herní průmysl. Aerospike poskytuje vlastní dotazovací jazyk AQL~\cite{aql}, který má velmi podobnou syntaxi jako SQL. AQL poskytuje možnost vytvoření vlastních flexibilních funkcí pomocí jazyku Lua, které mohou být vhodné pro agregační algoritmy.
	
	Dotazovací jazyk AQL se snaží zachovat standardní SQL syntaxi, obvyklé příkazy SELECT, INSERT, DELETE jsou tedy zachovány. Je možné vytvářet vlastní indexy nad tabulkami pomocí CREATE INDEX a provádět agregace pomocí AGGREGATE. Pro dotazy se záznamy specifikovanými pomocí hexadecimálního řetězce či Base64 lze v podmínce dotazu použít porovnání hodnoty s DIGEST nebo EDIGEST. Dotazování můžeme provádět i standardně nad primárním klíčem a ostatními atributy. Při vkládání záznamů lze specifikovat speciální datové typy atributů, jako je LIST, MAP, GEOJSON a další.
	
	\subsection{Oracle Berkeley DB} \label{lab-oracle-berkleydb}
	
	Oracle Berkeley DB~\cite{berkeleydb} je rodina vestavěných KDBS. Jedná se o čistě paměťový DBS~\cite{inmemory}, díky čemuž dosahuje vysokého výkonu a nízké odezvy. Databáze škáluje horizontálně. Data jsou replikována pro vyšší dostupnost a lepší toleranci chybovosti. Oracle Berkeley DB využívá vhodné datové struktury pro práci s daty, jako jsou B-strom~\cite{btree}, hashovací tabulka nebo fronta. Databáze využívá obnovitelné transakce~\cite{acid} a poskytuje několik různých úrovní izolace a MVCC~\cite{mvcc}. Data jsou rozdělena do oddílů dle rozsahu klíčů (key ranges). Databáze je Single-master, Multi-replica, tedy je vysoce dostupná a umožňuje dobrou konfigurovatelnost. Repliky umožňují čtecí škálovatelnost, rychlý fail-over~\cite{failover}, hot-standby~\cite{hotstandby} a další distribuované konfigurace, dodávající podnikové prostředky ve vestavěném balíčku. Failover je proces automatického nebo manuálního přepnutí na záložní systém, pokud dojde k výpadku primárního systému. Hot Standby je konfigurace, kde záložní systém nebo instance je plně synchronizovaný se systémem v reálném čase a je připraven převzít provoz okamžitě po selhání primárního systému. Pro přístup k datům a nastavení databáze se využívá jednoduché volání funkcí API. Mnoho moderních programovacích jazyků (např. C++, C\#, Java nebo Python) podporuje tuto KDBS. Data mohou být ukládána ve formátu XML nebo jako Java objekty, uložená data je také možné komprimovat. Oracle Berkeley DB se využívá jak pro lokálního úložiště tak i pro world-wide distribuovanou databáze.
	
	Interakce s Berkeley DB SQL API je prakticky identická jako s SQLite~\cite{sqlite}. Při práci s rozhraním BDB SQL~\cite{bdbsql} se také využívá stejné Shell prostředí, stejné příkazy SQL a stejné PRAGMA. BDB SQL rozšiřuje standardní SQLite PRAGMA o možnosti nastavení velikosti alokované paměti sdílených zdrojů, nastavení počtu bucketů, zvolení soukromého prostředí místo sdíleného, přesměrování logování chyb do vlastního souboru, nastavení příznaku, který způsobí, že sdílené prostředky databáze budou vytvořeny ve sdílené paměti systému a další. Dalším drobným rozdílem je, že BDB SQL rozhraní nepodporuje klíčové slovo IMMEDIATE~\cite{oracle-immediate} (např. příkaz EXECUTE IMMEDIATE spustí dynamický příkaz SQL nebo anonymní blok PL/SQL~\cite{pl-sql}).
	
	\subsection{Riak KV} \label{lab-riak}
	
	Riak KV~\cite{riak} je distribuovaná KDBS s lokální a multi-cluster replikací, která zvyšuje pravděpodobnost čtení a zápisu i v případě selhání hardwaru nebo síťových oddílů. Některé datové typy DBS Riak (flags, registry, čítače, množiny a mapy) jsou konvergentní replikované datové typy (CRDT~\cite{crdt, riakkv-crdt}), které umožňují nezávisle a souběžně aktualizovat jakoukoliv repliku v distribuované databázi se zajištěním sjednocení hodnot pomocí algoritmu, který je součástí samotného datového typu. Umožňuje konfiguraci běžícího clusteru a snižuje latenci díky dodávání dat z nejbližšího datacentra. KDBS provádí replikaci více clusterů~\cite{multicluster, riakkv-multiclustr} a využívá redundance dat v rámci geografické oblasti. Riak tedy automaticky distribuuje data skrz cluster, což může zlepšit robustnost a výkon distribuovaného DBS. KDBS poskytuje flexibilní datový model bez předem definovaného schématu. Databáze poskytuje logování chyb a reporty. Data jsou automaticky komprimována pomocí Snappy kompresní knihovny~\cite{snappy}. Databáze využívá master-less architekturu, je vysoce dostupná a má design horizontální škálovatelnosti. Škálovatelnost je téměř lineární při využití snadného přidání hardwarové kapacity bez nutnosti mnoha operací. Riak KV dovoluje zpracování dat pro analýzu a vyvození závěrů pro zlepšení chodu DBS. Riak KV je navržen pro nulové restrikce na hodnoty, takže session data mohou být enkódována mnoha způsoby a nevyžadují změnu schématu. Během nejvyšší zátěže nezhoršuje databáze zápis a horizontální škálovatelnost, uživatelé jsou stále obsluhováni bez problémů. Databáze je vhodná pro ukládání velkého množství nestrukturovaných dat, také pro big-data aplikace, ukládání dat z připojených zařízení a replikaci dat do okolí. Díky nízké latenci je DBS vhodný i pro chat/messaging aplikace. Riak KV exceluje v soukromém, veřejném či hybridním cloud nasazení.
	
	Riak KV API obsahuje veškeré CRUD operace pro správu objektů. Při vytváření nových objektů je potřeba nastavit typ a název bucketu, který skladuje klíče a data do něj vložená. Bucket má také vlastní indexy pro vyhledávání dat uvnitř něj. Dva různé buckety mohou uchovávat stejnou hodnotu klíče, ale jeden bucket obsahuje pouze unikátní klíče. Klíč pro data lze specifikovat explicitně vlastní při vytváření objektu pomocí parametru nebo při jeho absenci je datům přiřazen náhodný klíč. Při vkládání dat do DBS můžeme jednoduše nastavit parametr TTL daného objektu a také počet jeho replik. Při čtení dat můžeme před získáním výsledku zadat minimální počet replik, které se musí shodnout na stejných datech pro zvolený klíč. Pro efektivnější dotazy lze vytvořit vlastní indexy pro výchozí nebo námi zvolená datová schémata. Lze se dotazovat na data pro zvolený klíč nebo provádět fulltextové vyhledávání. Databáze poskytuje i funkce pro tvorbu sekundárních indexů a následné dotazy nad nimi. Riak API také umožňuje hlubší nastavení autorizace a bezpečnosti, práci s replikami a řešení konfliktů.
	
	\subsection{Voldemort}
	
	Project Voldemort~\cite{voldemort} je distribuovaná KDBS založena na Amazon DynamoDB. Škáluje horizontálně pro čtení i zápis. Umožňuje zapojení vybraného storage-enginu (např. MySQL~\cite{mysql} nebo Read-Only). Databáze automaticky replikuje data napříč servery pro dostupnost a bezpečnost jednotlivých oddílů při vysoké propustnosti, nicméně každý server obsahuje pouze část z celkových dat. Databáze je decentralizovaná z pohledu uzlů, každý uzel je samostatný a nezávislý, nenachází se zde žádný centrální řídící uzel nebo uzel řídící řešení chyb. Voldemort má výkonost desítek tisíc operací za sekundu na jeden uzel (1 op. za 50 mikrosekund), samozřejmě závisí na hardwaru, síti, systému disku atp. Konzistence dat je nastavitelná (přísné kvórum nebo případná konzistence). Selhání serverů jsou ošetřována transparentně, pro lepší viditelnost, interní monitorování a validaci dat lze využívat JMX~\cite{jmx}. Data jsou verzována pro maximální integritu i během poruch. In-Memory caching pro eliminaci oddělených částí cache, jednoduché a rychlé in-memory testování (např. pro unit testy). Databáze umožňuje jednoduchou distribuci dat skrz stroje, data mohou být rozdělována například dle primárních klíčů. Databáze má hashovatelné schéma, vyhledávání dle primárního klíče a možnost modifikace jednotlivých hodnot. Voldemort poskytuje široké možnosti pro klíče i hodnoty díky serializaci včetně listů a tuplů s pojmenovanými poli. Pro serializaci (Java Serialization, Thrift, Avro) se využívá JSON datový model v kompaktním bytovém formátu, probíhá zde typová kontrola dat dle očekávaného schématu. Pomocí API je možné rozhodovat o replikování a místech ukládání dat, nastavení různé strategie pro specifické aplikace a možnost distribuce dat skrz data centra která jsou mezi sebou geologicky velice vzdálená. Databáze neposkytuje triggery, cizí klíče ani komplexní filtry pro dotazy.
	
	Práce s Voldemort databází z pohledu klienta je přímočará, API se skládá pouze z pár základních funkcí pro správu dat. Tyto funkce jsou Put, Get a Del pro nastavení, získání a odstranění hodnot pro explicitně specifikovaný klíč. Funkce GetAll umožňuje obdržet více hodnot pro více specifikovaných klíčů pomocí volání pouze jedné funkce, GetAll dosahuje vyšší propustnosti než zřetězené volání samostatné funkce Get. Pro připojení k Voldemort databázi a nastavení výchozího uzlu úložiště se využívá funkce Bootstrap, bez nastavení výchozího uzlu je potřeba specifikovat uzel explicitně před každým voláním funkce Get a dalších. Pro funkci Bootstrap je také možné nastavovat serializer pro klíče i hodnoty, čas spojení klienta se serverem a interval automatické změny uzlu v rámci clusteru na ten nejvhodnější. Pro ukončení komunikace se využívá jednoduše funkce Close.
	
	\subsection{InfinityDB}
	
	InfinityDB~\cite{infinitydb} je NoSQL hierarchicky tříděná KDBS implementovaná v jazyce Java. Databáze má možnost využít čistě In-Memory~\cite{inmemory} ukládání dat, která je vhodné pro cache, nebo naopak se mohou data ukládat i perzistentně na disk do souboru, přičemž je možné měnit nastavení bez zasahování do kódu. Přístup k datům v cache je plně vícevláknový, využívá se většina jader, a data, která nejsou často využívaná, jsou stránkována na disk. Databáze dosahuje výkonu v jednotkách milionů operací za sekundu pro více vláknové operace v cache. Veškerá data a informace o databázi jsou uložena na disku v jednom souboru, což zajišťuje jejich aktuálnost a zároveň maximalizuje bezpečnost a korektnost. Databáze je designována právě pro použití jednoho kompletního souboru s okamžitým zotavením a nevyžaduje proto administraci. Databáze neobsahuje dodatečné konfigurační nebo dočasné soubory, upgrade skripty ani logy. Zotavení je bez logů o transakcích okamžité ihned po restartu. V databázi není potřeba dělat čištění junk souborů po operacích, když zde nejsou žádné zanechány. InfinityDB podporuje ACID pro vlákna a ACD pro bulk operace. Databáze poskytuje prostor pro ukládání strukturovaných, polo-strukturovaných a nestrukturovaných dat. Tento jednoduchý model umožňuje ukládání vnořených Multi-values a je možné reprezentovat různé datové struktury, jako jsou stromy, grafy, key/value mapy, dokumenty, velká řídká pole a tabulky. Schema je možné měnit za běhu pro zpětnou i následující kompatibilitu. Data dotazů lze dynamicky sledovat pomocí set logic views, delta views a ranges. Databáze se využívá pro servery, pracovní stanice a příruční zařízení.
	
	InfinityDB poskytuje základní jednoduché API o deseti hlavních voláních. Funkcionalitu pro vkládání, úpravu a mazání hodnot zajišťují funkce Insert, Update a Delete. Funkce Delete je rozšířena o funkci Delete-suffixes, která umožňuje odstranit více hodnot v jednom volání. Pro získávání hodnot se využívá kurzoru, jehož pohyb v obou směrech zajišťují funkce First, Next, Last a Previous. Nakonec jsou k dispozici také potřebné funkce Commit a Rollback pro možnost využívání transakcí.
	
	\subsection{Memcached} \label{lab-memcached}
	
	Memcached~\cite{memcached} je open-source, distribuované, in-memory key-value úložiště, navržené pro rychlý a efektivní caching~\cite{cachovani}. Primárním účelem Memcached je uchovávání často používaných dat v paměti, aby se snížila latence a zvýšila rychlost přístupu k nim. Jeho jednoduchý a efektivní přístup k ukládání a získávání dat ho činí populární volbou pro webové servery, kde je potřeba rychle cachovat často používané informace jako například HTML stránky, databázové dotazy nebo výpočty. Memcached funguje jako distribuovaná cache, díky čemuž může být nasazen na více serverech, a data jsou mezi nimi rovnoměrně distribuována. Tento přístup umožňuje horizontální škálování, takže kapacitu a výkon Memcached lze jednoduše rozšiřovat přidáním dalších serverů.
	
	Jednou z klíčových vlastností této KDBS je jeho jednoduché API, které podporuje základní operace s key-value páry, jako je ukládání, získávání a mazání dat. Tato funkcionalita je dostupná pomocí funkcí SET, GET, ADD, REPLACE a DELETE. Díky tomu je integrace Memcached do existujících aplikací relativně snadná a není vyžadována žádná složitá konfigurace. Memcached také poskytuje možnost nastavení expirace dat, což umožňuje automatické odstranění zastaralých dat z cache a uvolnění paměťových prostředků. Tato funkce je užitečná zejména pro udržování čerstvých a aktuálních dat v cache. Další významnou vlastností Memcachedu je jeho podpora distribuovaných transakcí, která umožňuje atomické operace nad více key-value páry. Pro práci s touto KDBS jsou k dispozici knihovny pro různé programovací jazyky, což usnadňuje jeho integraci do široké škály aplikací a systémů. Díky své jednoduchosti, efektivitě a škálovatelnosti je Memcached oblíbenou volbou pro mnoho webových aplikací a služeb.

	\begin{sidewaystable}
		\centering
		%\rotatebox[origin=c]{180}{
		%\caption{Porovnání Key-value databází\label{tab_kvdb_compare}}
		\scalebox{0.8}
		{
			\begin{tabular}{ l|c c c c c c c c } 
				\toprule
				Databáze & Amazon & Oracle & Redis & Aerospike & Oracle & Riak & Voldemort & InfinityDB \\
				& DynamoDB & NoSQL DB & & & Berkeley DB & KV & & \\
				\midrule
				Čistě cloud & ano & ne & ne & ne & ne & ne & ne & ne \\
				Schéma dat & ne & ano i ne & ne & ne & ne & ne & ne & ano \\
				Licence & komerční & open source & open source & open source & open source & open source & open source & komerční \\
				Server OS & hostovaná & Linux, Solaris & Linux, Windows, & Linux & Linux, Windows, & Linux, OS X & Linux, Windows &  Linux, Windows, \\
				& & & OS X, BSD & & OS X, Android ad. & & & OS X, Solaris\\
				Napsáno v & - & Java & C & C & C, C++, Java & Erlang & Java & Java\\
				Sekundární & ano & ano & ano & ano & ano & omezené & ne & ne \\
				indexy & & & & & & & & \\
				Koncept & ACID & ACID & atomické, & atomické & ACID & ne & ne & ACID \\
				transakcí & & v rámci uzlu & izolované & & & & & \\
				Triggery & ano & ne & pub/sub & ne & ano & ano & ne & ne \\
				Dělící & sdílení & sdílení & sdílení & sdílení & ne & sdílení & ne & ne \\ 
				metody \\
				Replikační & ano & source-replica & source-replica, & volitelná & source-replica & volitelný & ne & ne \\
				metody & & multi-region & multi-source & faktor repl. & & faktor repl. \\
				Administrace & vysoká & nízká & vysoká & vysoká & vysoká & vysoká & vysoká & ne\\
				Škálovatelnost & horizontální & horizontální & horizontální & lineární & horizontální & lineární & horizontální & horizontální\\
				Odezva & mikrosekundy & milisekundy & milisekundy & milisekundy & mikrosekundy & milisekundy & milisekundy & milisekundy \\
				Dotazovací & PartiQL & Omezený SQL & Redis & AQL & SQL & Riak & Voldemort & InfinityDB \\
				jazyk & & & query & & & query & query & query \\
				\bottomrule
			\end{tabular}}%}
			\caption{Porovnání Key-value databází\label{tab_kvdb_compare}}
		
	\end{sidewaystable}
	
	\subsection {Nezmíněné významné NoSQL databáze}
	
		Do práce nebyly záměrně zahrnuty databázové systémy MongoDB a Couchbase~\cite{mongodb,couchbase}. I když se jedná o známé a hojně využívané NoSQL databáze, byly obě záměrně vynechány z práce, protože mají Key-value model až jako sekundární datový model. Primárně jsou určeny pro ukládání dokumentově orientovaných informací~\cite{documentdb}. Tato práce se zaměřuje na porovnání výhradně KDBS. Další často využívanou a nezmíněnou NoSQL databází je Cassandra~\cite{cassandra}, která udává jako datový model wide-column store~\cite{widecolumnstore}. Z tohoto důvodu byl i tento DBS vyřazen z testování.
	
	\chapter{Prostředí pro testování databázových systémů\label{chapter:3-test_environment}}
	
	Různé databázové systémy mohou přistupovat k řešení jednotlivých problémů odlišně. Pokud chceme rozhodnout, který z těchto systémů je nejvhodnější pro určité úkoly, musíme provést řadu testů a porovnání. Je prakticky nemožné nalézt ideální databázový systém, který by exceloval ve všech aspektech pro všechna data a případy použití. Testování nám umožní odhalit, který systém vyniká a naopak zaostává pro konkrétní operace nad konkrétními daty. Proto je důležité najít ideální prostředí pro měření a porovnání vlastností vybraných KDBS z kapitoly~\ref{chapter:no-sql-ky-sys}.
	
	Aktuálně existuje celá řada nástrojů pro měření výkonu databázových systémů~\cite{dbs-testing-tools}. Mezi dva využitelné a bezplatné nástroje se řadí například TPC~\cite{tpc} a YCSB~\cite{ycsb}. TPC od organizace Transaction Processing Performance Council se dělí do mnoha kategorií. Například TPC-H je považován spíše za benchmark pro systémy pro podporu rozhodování~\cite{dss}, zatímco TPCx-BB je benchmark pro Big Data. Obecně se TPC benchmarky využívají spíše pro RDBS. Na druhou stranu Yahoo! Cloud Serving Benchmark (dále jen YCSB) od společnosti Yahoo! je open-source specifikace a sada programů pro vyhodnocování možností vyhledávání a údržby počítačových programů. Často se ale právě YCSB používá k porovnání výkonu NoSQL databázových systémů~\cite{benchmark-pdf-1, benchmark-pdf-2}, což je pro tuto práci zaměřenou na KDBS ideální. Proto bylo v této práci toto testovací prostředí zvoleno pro měření výkonu jednotlivých DBS.
	
	\section{YCSB} \label{lab-ycsb}
	
	Architektura YCSB~\cite{ycsb,ycsb-benchmarking} je založena na pluginech a poskytuje snadnou rozšiřitelnost pomocí skriptů. Pro značnou část významných databázových systémů existuje podpora v podobě bindingů~\cite{ycsb}. Samotný benchmark se skládá ze dvou fází. První z nich je Loading fáze zaměřená na vložení dat do databáze a následně druhá je Running fáze, ve které se spouští daný test (viz schéma~\ref{ycsb-blok-schema}).
	
	Při spouštění každého testu je možné nastavit určité parametry (viz kapitola~\ref{test-param} a~\ref{test-start}) pro lepší konkretizaci měřeného scénáře~\cite{ytb-ycsb}. První a druhý parametr slouží pro specifikaci loading nebo running fáze a výběr testovaného databázového systému. Následně se vybírá testovaný scénář vytížení (Workload), počet záznamů v databázi, počet atributů daného záznamu, bytovou velikost každého atributu v záznamu, počet vláken, umístění serveru databáze a nakonec distribuci dotazů (uniformní, exponenciální, sekvenční, nejnovější, hotspot, definované).
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.85]{Data/ycsb-1.jpg}
		\caption{YCSB rámec testování funkčnosti \cite{ycsb-parallel-data-lab}\label{ycsb-blok-schema}}
	\end{figure}
	
	V YCSB se typicky používá uměle generovaná sada dat, která simuluje běžné operace nad databází. Tato data obvykle obsahují záznamy, kde každý záznam má jedinečný klíč a přidruženou hodnotu. Klíče jsou řetězce generované náhodně nebo podle určitého rozložení (např. uniformního a zipfovského~\cite{zipf-dist}), aby bylo možné simulovat různé typy zatížení. Velikost klíče je nastavitelná. Vygenerované klíče mohou být například "user1274"~nebo "record7891". Hodnota je JSON dokument, který obsahuje několik polí. Každé pole je pojmenováno jako "fieldX", kde X je číslo od 0 do N (výchozí nastavení zahrnuje 10 polí). Hodnoty polí jsou řetězce obsahující náhodná data nastavené velikosti.
	
	YCSB poskytuje 5 různých scénářů označených A až F pro testování propustnosti, latence a škálovatelnosti jednotlivých databázových systémů. Tyto pracovní scénáře, neboli Workloads~\cite{benchmark-pdf-1, workloads}, napodobují různé chování požadavků webových aplikací, jako jsou scénáře zaměřené výhradně na čtení, zápis, aktualizace, mazání nebo kombinace zmíněných operací. Dle výchozího nastavení se do DBS vloží 1000 záznamů a testuje se 1000 operací. Počet záznamů v DBS společně s počtem provedených operací lze změnit prostřednictvím parametrů "recordcount"~a "operationcount".
	
	Při testování kombinace různých operací je jejich konkrétní počet definován dle procentuálního poměru všech operací, tento poměr definuje zvolený Workload. Například při výchozím nastavení, kde je počet operací 1000 a zvolení scénáře Workload B zaměřeného převážně na čtení, budeme provádět 950 operací čtení a 50 aktualizací. Právě protože 95\% ze všech operací je v tomto scénáři zaměřeno na čtení a 5\% na aktualizace. Při rozsahových dotazech ve Workloadu E je maximální počet procházených záznamů v jedné operaci definován jako 5\% z celkového počtu záznamů. Takže při počtu záznamů 1000 bude každá operace rozsahového dotazu číst právě 1 až 50 záznamů.
	
	\begin{itemize} \label{lab-workloads}
		\item Workload A (Update heavy)
		\begin{itemize}
			\item 50\% operací zaměřených na čtení a 50\% operací zaměřených na úpravu
		\end{itemize}
		\item Workload B (Read mostly)
		\begin{itemize}
			\item 95\% operací zaměřených na čtení a 5\% operací zaměřených na úpravu
		\end{itemize}
		\item Workload C (Read only)
		\begin{itemize}
			\item 100\% operací zaměřených na čtení
		\end{itemize}
		\item Workload D (Read latest)
		\begin{itemize}
			\item 95\% operací zaměřených na čtení, 5\% operací zaměřených na vkládání a poslední vložené záznamy jsou čteny přednostně
		\end{itemize}
		\item Workload E (Short ranges)
		\begin{itemize}
			\item 95\% operací zaměřených na rozsahové skenování nízkého počtu záznamů a 5\% operací zaměřených na vkládání
		\end{itemize}
		\item Workload F (Read-modify-write)
		\begin{itemize}
			\item každá operace se skládá z čtení daného záznamu, úpravy záznamu a následného vložení změněného záznamu zpět
		\end{itemize}
	\end{itemize}
	
	Testované operace jsou definovány prostřednictvím JSON dokumentů. Tento dokument obsahuje informace o typu operace (read, insert, update a delete), názvu tabulky, klíči a případně i názvech polí a jejich hodnotách. Například dotaz v první ukázce (viz dokument na obrázku~\ref{json-ycsb-operace-read}) načte hodnoty polí "field0"~a "field1"~záznamu s klíčem "user1474"~z tabulky "usertable". Dotaz v druhé ukázce (viz dokument na obrázku~\ref{json-ycsb-operace-insert}) vloží nový záznam s klíčem "user1474"~a hodnotami "field0", "field1"~a "field2"~do tabulky "usertable".
	
	\begin{figure}[H]
	\centering
	\begin{lstlisting}[language=json,firstnumber=1]
{
  "operation": "read",
  "table": "usertable",
  "key": "user1474",
  "fields": ["field0", "field1"]
}
	\end{lstlisting}
	\caption{YCSB - příklad čtení záznamu}
	\label{json-ycsb-operace-read}
	\end{figure}	
	
	\begin{figure}[H]
		\centering
		\begin{lstlisting}[language=json,firstnumber=1]
{
  "operation": "insert",
  "table": "usertable",
  "key": "user1474",
  "values": {
    "field0": "value0",
    "field1": "value1",
    "field2": "value2"
  }
}
		\end{lstlisting}
		\caption{YCSB - příklad vložení záznamu}
		\label{json-ycsb-operace-insert}
	\end{figure}	
	
	\section{TPC}
	
	Transaction Processing Performance Council~\cite{tpc}, dále jen TPC, je společnost spravující software pro vytváření benchmarků výkonnosti systémů pro online zpracování transakcí (OLTP)~\cite{oltp} a možnosti jejich následného monitoringu a porovnávání. TPC benchmarky využívají firmy s velkými data a přiměřenou zátěží, výsledkem benchmarků je počet transakcí za minutu (tpm).
	
	TPC benchmarky jsou rozděleny do více modelů pro různě specifikované testy. Prvním z modelů pro OLTP byl TPC Benchmark A (TPC-A), který následně nahradil benchmark TPC-B a aktuálně se v tomto odvětví využívá poslední generace OLTP benchmarků TPC-C a TPC-E. Například modely TPC-DS/DI a TPC-H jsou uzpůsobeny pro testování systémů pro podporu rozhodování~\cite{dss}. TPC benchmarky jsou přizpůsobeny i pro virtualizaci, IoT~\cite{iot} a další (viz tabulka TPC benchmarků~\ref{tab_tpc_modely}).
	
	Při spouštění TPC testů si nejprve zvolíme požadovaný scénář obsahující sadu SQL příkazů. Tyto příkazy se následně provádějí, ideálně nad velkými daty. TPC benchmark nakonec vyhodnotí výkon DBS~\cite{tpc-ytb-benchmark} na základě naměřených hodnot v testovaném scénáři. Pro komplexní testování SQL příkazy často obsahují náročné operace, jako například agregace, seřazení, průměry, spojení tabulek nebo vnořené dotazy~\cite{tpc-h-sql, tpc-h-index} (viz první SQL Test Q1 pro TPC-H~\ref{tpc-h-sql}).
	
	\begin{figure}[h]
		\centering
		\begin{lstlisting}[
			language=SQL,
			showspaces=false,
			basicstyle=\ttfamily,
			numbers=left,
			numberstyle=\tiny,
			commentstyle=\color{gray},
			frame=lines,
			backgroundcolor=\color{background}
			]
 --Q1
 select
   l_returnflag,
   l_linestatus,
   sum(l_quantity) as sum_qty,
   sum(l_extprice) as sum_base_price,
   sum(l_extprice * (1 - l_discount)) as sum_disc_price,
   sum(l_extprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,
   avg(l_quantity) as avg_qty,
   avg(l_extprice) as avg_price,
   avg(l_discount) as avg_disc,
   count(*) as count_order
 from lineitem
 where  l_shipdate <= date '1998-12-01'
 group by  l_returnflag,  l_linestatus
 order by  l_returnflag,  l_linestatus;
		\end{lstlisting}
		\caption{TPC-H, SQL Test Q1~\cite{tpc-h-sql, tpc-h-index}
			\label{tpc-h-sql}}
	\end{figure}
	
	Model TPC-C~\cite{tpc-c} simuluje velkoobchodní provoz s více sklady, známý jednoduše jako "společnost". V minimálním testu má společnost deset skladů, každý s deseti uživatelskými terminály. Každý sklad obsluhuje deset definovaných prodejních okrsků, každý s 3000 zákazníky, kteří objednávají podle katalogu výrobků o 100 000 položkách. Nejčastějšími transakcemi jsou objednávky zákazníků, přičemž každá objednávka obsahuje v průměru 10 položek, a platby zákazníků. Méně časté požadavky se dotazují na stav objednávek a skladových zásob, expedují objednávky a doplňují zásoby, které se sníží. Pro testování výkonnosti daného systému se počet skladů zvyšuje tak, aby splňoval požadované minimum potřebné k měření cílové úrovně výkonnosti.
	
	Výsledky srovnávacího testu se měří v transakcích za minutu, známých jako tpmC. První výsledek tpmC byl zveřejněn v září 1992 pro IBM AS/400 a přinesl výsledek 54 tpmC. V roce 2000 byl průměrný výsledek pro špičkové stroje 2,4 milionu tpmC~\cite{tpc-rec-2000}, a společnosti ve snaze získat rekord stavěly systémy velkých rozměrů. Současný rekord byl stanoven v roce 2020 pomocí cloud computingu, který poskytl 707,3 milionu tpmC~\cite{tpc-c-top-result}. Nedávné výsledky pro menší lokální systémy se zaměřily na snížení nákladů na tpmC.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l }
			\toprule
			TPC benchmark & využití\\
			\midrule
			TPC-C, TPC-E & zpracovávání transakcí \\
			TPC-H, TPC-DS, TPC-DI & podpora rozhodování \\
			TPCx-V, TPCx-HCI & virtualizace \\
			TPCx-HS, TPCx-BB & velká data \\
			TPCx-IoT & IoT \\
			TPCx-AI & umělá inteligence \\
			TPC-Energy, TPC-Pricing & běžné specifikace \\
			TPC-A, TPC-B, TPC-APP, TPC-D & zastaralé benchmarky \\
			TPC-R, TPC-W, TPC-VMS & \\
			\bottomrule
		\end{tabular}
		\caption{TPC benchmarky\label{tab_tpc_modely}}
	\end{table}
	
	\section{Relevance TPC a YCSB pro měření KDBS}
	
	Pokud jde o relevanci TPC pro KDBS, je potřeba brát v úvahu, že KDBS se liší od tradičních relačních databází. Zatímco TPC benchmarky se zaměřují na transakční zpracování a složitější operace typické pro RDBS (viz SQL Test Q1 z TPC-H~\ref{tpc-h-sql}), KDBS se používají pro přístup k datům pomocí jednoduchého klíč-hodnota rozhraní a jsou často součástí aplikací s vysokým objemem operací typu čtení a zápisu.
	
	Z tohoto důvodu by benchmarky navržené specificky pro KDBS byly relevantnější pro měření jejich výkonnosti a charakteristik. Nicméně některé aspekty TPC benchmarků, jako je zátěžové testování nebo schopnost zpracovávat vysoký objem transakcí u RDBS, mohou poskytnout užitečné informace i pro KDBS, i když TPC benchmarky nejsou primárně určeny pro KDBS.
	
	YCSB poskytuje sadu připravených scénářů~\cite{workloads} a operací~\cite{ycsb-properties}, které simulují reálné aplikace a zátěžové podmínky. Obecně lze říci, že YCSB je díky svému klíč-hodnota rozhraní vhodný nástroj pro testování KDBS a poskytuje užitečné informace o jejich výkonu a škálovatelnosti ve scénářích podobných reálnému použití.
	
	\chapter{Vyhodnocení výsledků testů\label{chapter:4-test_results}}
	
	\section{Testovací stroj}
	
	Veškeré testy byly spouštěny na vlastním stroji, domácím počítači. Stroj disponoval procesorem Intel~Core~i5~4590 s taktem 3,3~GHz a 8~GB operační pamětí RAM. Všechny aplikace byly nainstalovány a spouštěny na SSD disku Samsung~870~EVO. Konkrétní specifikace tohoto stroje jsou uvedeny v tabulce~\ref{tab_my_pc_spec}. Testovalo se na operačním systému Windows, avšak s úpravou lomítek ve skriptech jsou skripty a prostředí YCSB i Docker kompatibilní i pro OS Linux.
	
	\begin{table}
	\centering
	\caption{Specifikace stroje na kterém se spouštěly testy\label{tab_my_pc_spec}}
		\begin{tabular}{ l | l | l } 
			\toprule
			komponent & název & podrobnosti \\
			\midrule
			OS & Microsoft Windows 10 PRO & x64 \\
			CPU & Intel Core i5 4590 & 3,3GHz (Boost 3,7GHz), core/thread 4, Haswell\\
			GPU & NVIDIA GeForce GTX 1660 SUPER & 6GB, 1530MHz (Boost 1785MHz) \\
			RAM & Crucial Ballistix Sport & 8GB (2x4GB), 1600MHz, DDR3 \\
			SSD & Samsung 870 EVO & R/W 560/530MB/s, 1TB, TLC, SATA 6Gb/s \\
			Základní deska & GIGABYTE GA-H81M-H - Intel H81 & 1150 socket, DDR3 DIMM \\
			\bottomrule
		\end{tabular}
	\end{table}

	\section{Zprovoznění testů}
	
	Pro rozsáhlé otestování byly vybrány čtyři vhodné KDBS. A to konkrétně Redis (viz kapitola~\ref{lab-redis}), Riak KV (viz kapitola~\ref{lab-riak}), Aerospike (viz kapitola~\ref{lab-aerospike}) a Memcached (viz kapitola~\ref{lab-memcached}). Všechny tyto KDBS byly zvoleny na základě vysoké relevance a jednoho z nejlepších umístění podle žebříčku na webu DB-Engines Ranking~\cite{db-engineers-ranking} pro aktuální rok 2024.
	
	Ve snaze o možnost replikace testů byly všechny databáze instalovány a spouštěny pomocí open-source platformy Docker~\cite{docker}. Bylo tedy nutné najít vhodný a kompatibilní Docker Image pro každou z testovaných databází. V kontextu této práce Docker pomáhá zrychlit zdlouhavou fázi instalování a nastavení počátečního stavu databází, udržení funkčnosti vybrané verze instalovaného softwaru a odstínění od stavu stroje, na kterém DBS spouštíme.
	
	Veškeré testy byly vytvářeny a spouštěny pomocí frameworku YCSB (\ref{lab-ycsb}). YCSB framework v první části, Load, do databáze vložil data, a následně v druhé části, Run, spustil testy a vrátil hodnoty výsledků. Pomocí přidání volitelných parametrů~\cite{ycsb-properties} bylo možné testy upravit podle vlastních potřeb.
	
	Po spuštění databáze v prostředí Docker se k ní připojil YCSB framework, který následně prováděl testování nad zvolenou připojenou databází. Pro možnost komunikace bylo zapotřebí zprovoznit YCSB binding pro každou z databází, aby YCSB framework mohl úspěšně komunikovat se zvolenou databází, vložit data, spustit testy a vrátit patřičné výsledky. 
	
	Pro každý KDBS bylo nutné najít funkční a kompatibilní verzi, kterou podporuje YCSB. K tomuto výběru pomohly chybové hlášky, které YCSB poskytuje při pokusu o připojení k dané KDBS. Spousta problémů se dala dohledat v sekci nahlášených chyb na oficiálním GitHubu~\cite{ycsb} projektu YCSB nebo na fórech, jako je například StackOverflow~\cite{stackoverflow-ycsb}. Nejprve se pracovalo s OS Linux kvůli větší podpoře YCSB projektu na této platformě. Následně se přešlo na OS Windows kvůli neschopnosti zprovoznění celého projektu na Linuxu. Na OS Windows se projekt nejprve spouštěl prostřednictvím WSL~\cite{wsl-microsoft}, převážně kvůli KDBS Redis, která nepodporuje Windows. Bylo tedy zapotřebí nastavit a zprovoznit WSL. Nakonec po úspěšném zprovoznění se přešlo na Docker, kde bylo několik problémů. Nejprve docházelo k pádům prostředí Docker po připojení KDBS k YCSB. Následně docházelo k chybám způsobeným špatnou verzí Javy a chybějícímu nastavení systémových proměnných Windows. Nakonec bylo zapotřebí vyřešit problém s nemožností komunikace s některými KDBS. Tento problém byl vyřešen po přenastavení portů v prostředí Docker. Tyto porty byly nalezeny v dokumentaci YCSB v sekci popisu vybraných KDBS a jejich zprovoznění. U některých KDBS bylo ještě zapotřebí přenastavit jejich konfigurace, zejména u KDBS Riak KV, kde se musela změnit úroveň konzistence a typ úložiště. U KDBS Memcached docházelo k přerušení komunikace během dlouhých testů, takže se musel zvýšit čas vypnutí této KDBS.
	
	Skripty potřebné k nastavení KDBS v prostředí Docker, zprovoznění a připojení k YCSB a následnému spuštění testů jsou dostupné v textovém souboru "YCSB\_Docker\_Scripty.txt"~\cite{skripty-soubor}. Tento soubor je součástí příloh odevzdaných k diplomové práci. Začátek souboru obsahuje odkazy pro získání potřebného softwaru k spuštění testů. Následuje stručný popis testových scénářů Workload~A~-~F. Poté následují skripty pro spuštění zkušební verze, která nevyžaduje nastavení vlastního DBS. Místo toho se spustí ukázkové testy, jejichž výsledek je vypsán do konzole pro možnost kontroly korektního nastavení YCSB. Soubor je zakončen čtyřmi kategoriemi pro každou z testovaných KDBS. Součástí testovacích skriptů každé KDBS jsou dvě sekce zaměřené na příkazy potřebné pro prostředí Docker a YCSB. Docker část obsahuje skripty pro stažení, spuštění, zastavení a odstranění jednotlivých KDBS prostřednictvím prostředí Docker. YCSB část poskytuje skripty pro naplnění KDBS daty a spuštění testů vybraných scénářů v prostředí YCSB.
	
	\section{Popis parametrů testů}\label{test-param}
	
	Veškeré testy pro každou z testovaných databází byly spuštěny třikrát, a finální výsledek byl tedy průměrem ze všech tří testů pro každou databázi v dané testovací kategorii. Každý test byl spouštěn paralelně na čtyřech vláknech.
	
	Do databáze bylo vždy vloženo 100~000 záznamů a následující test prováděl 1~000~000 dotazů (viz kapitola~\ref{lab-ycsb}). Následně po dokončení testů byla databáze smazána, aby bylo možné naplnit ji novými, neaktualizovanými daty, a celý proces se opakoval ještě dvakrát. Každý záznam se skládá z klíče a hodnoty, které jsou uloženy v tabulce s názvem "usertable". Klíč je řetězec v podobě "userX", kde X reprezentuje unikátní číslo daného záznamu. Hodnota každého záznamu je v podobě JSON dokumentu s 10 poli pojmenovanými jako "field0"~až "field9", kde každé pole obsahuje jeden řetězec s podobou "value0"~až "value9". Celková velikost všech záznamů je 101~MB (a například při použití KDBS je overhead~\cite{overhead-pcmag} přibližně 10~\% a celková velikost dat pak činí přibližně 111~MB).
	
	Testy byly prováděny ve třech YCSB kategoriích (tzv. YCSB Workload~\cite{workloads}). Workload A (Update-heavy: 50\% čtení, 50\% aktualizace), Workload B (Read-mostly: 95\% čtení, 5\% aktualizace) a Workload C (Read-only) (viz kapitola~\ref{lab-workloads}).
	
	Při aktualizacích dojde ke změně hodnot všech 10 polí vybraného záznamu. Definice aktualizace je uvedena v ukázce JSON dokumentu na obrázku~\ref{json-ycsb-operace-update}. V této aktualizaci se přistupuje k tabulce "usertable"~a pomocí klíče "user1474"~se aktualizují všechny hodnoty v polích "field0"~až "field9"~na hodnoty "new\_value0"~až "new\_value9".
	
	\begin{figure}[H]
	\centering
	\begin{lstlisting}[language=json,firstnumber=1]
{
  "operation": "update",
  "table": "usertable",
  "key": "user1474",
  "values": {
    "field0": "new_value0",
    "field1": "new_value1",
    ...
    "field9": "new_value9"
  }
}
	\end{lstlisting}
	\caption{YCSB - příklad aktualizace záznamu}
	\label{json-ycsb-operace-update}
	\end{figure}
	
	Pro každý Workload a jednotlivé databáze byla vytvořena tabulka výsledků jednotlivých testů a výsledný průměr těchto testů. Mezi nejdůležitější výsledky testů patří celková doba trvání testu, propustnost a percentily latence operací, konkrétně 95. a 99. percentil. V tabulce jsou také data o počtu provedených operací, průměrné latenci operací, a také minimální, průměrná a maximální latence operací.
	
	Určité databáze vyžadují i další parametry pro spuštění testování, nejčastěji to jsou host IP adresy nebo porty dané databáze pro možné spojení. Dále je například možné specifikovat cestu k souborům, se kterými pracuje testovací prostředí, nebo stanovit TTL~\cite{ttl} testovaných dat, aby bylo možné vyhnout se expiraci dat při dlouhotrvajících nebo vzájemně opožděných testech.
	
	\section{Spouštění testů}\label{test-start}
	
	Pro spuštění testů je nejprve zapotřebí nainstalovat, nastavit a spustit vybranou databázi. Poté se musíme k DBS připojit pomocí testovacího prostředí YCSB pro možnou komunikaci s databází a naplnit ji daty. Nakonec spustíme požadované testy a po dokončení testování nám prostředí YCSB vrátí tabulku výsledků v textové podobě.
	
	Nainstalujeme platformu Docker~\cite{docker-console} pro snadnou práci s instalovanými databázemi. Pokud chceme využívat grafického rozhraní pro prostředí Docker, je možnost také instalace platformy Docker Desktop~\cite{docker-desktop, docker-cli} (případně si samozřejmě můžeme DBS instalovat i jiným pro nás vhodnějším způsobem). Docker Desktop bych doporučil pro práci s databázemi, u kterých se plánuje větší úprava konfiguračních souborů nebo sledování chování DBS za běhu prostřednictvím logování.
	
	Práce s Docker Desktop je velice intuitivní, proto se zaměříme na práci s Docker CLI~\cite{docker-cli}. Po zvolení vhodné databáze si musíme stáhnout Docker Image~\cite{docker-image-container} této databáze~\cite{docker-hub} pomocí příkazu "docker~image~pull~[OPTIONS]~NAME[:TAG|@DIGEST]"~\cite{docker-image-pull}. Druhým krokem je nastavení a spuštění DBS. Vytvoříme tedy pomocí Docker Image náš Docker Container~\cite{docker-image-container} který spustíme příkazem "docker~container~run~[OPTIONS]~IMAGE~[COMMAND]~[ARG...]"~\cite{docker-container-run}. Nesmíme zapomenout nastavit správné čísla portů pro Docker Container, jinak nebude testovací prostředí YCSB schopno komunikovat s Docker Image. 
	
	Testovací prostředí YCSB je možné získat z oficiálního GitHub repozitáře Yahoo! Cloud Serving Benchmark~\cite{ycsb}. Pokud nechcete manuálně překládat zdrojové kódy projektu pro možnost nasazení vlastních změn, je vhodné stáhnout funkční verzi, která je k dispozici na odkazu uvedeném v README souboru~\cite{ycsb-download}. Pro úspěšné sestavení projektu ze zdrojových kódů je zapotřebí mít nainstalovaný Apache Maven~\cite{maven} ve verzi 3. Pokud je na stroji nainstalována verze Maven 2, může docházet k chybám (aktuální verzi Mavenu můžete zkontrolovat pomocí příkazu "mvn~-version"). Dále je zapotřebí mít nainstalované Java JDK ve verzi 8 (1.8)~\cite{java-jdk} a vyšší. Na operačním systému Windows doporučuji zkontrolovat hodnotu systémové proměnné "\%JAVA\_HOME\%", abyste se ujistili, že je nastavena správně. To můžete udělat pomocí příkazu "echo~\%JAVA\_HOME\%". Pokud tato systémová proměnná není nastavena správně, musíte ji manuálně změnit (správně nastavená proměnná by měla obsahovat cestu k nainstalovanému Java JDK s verzí minimálně 1.8, například  "C:$\backslash$Program Files$\backslash$Java$\backslash$jdk1.8.0\_231").
	
	Po úspěšném zprovoznění testovacího prostředí YCSB a nastavení DBS v prostředí Docker, můžeme začít spouštět testy. Nejprve musíme do databáze vložit data a následně spustit testy. Veškeré testy byly spouštěny prostřednictvím námi vytvořených skriptů (viz přiložený soubor "YCSB\_Docker\_Scripty.txt"~\cite{skripty-soubor}) vložených do příkazového prostředí Windows PowerShell~\cite{win-powershell}. Nicméně není problém tyto skripty spouštět i v obyčejném příkazovém řádku. Jen zde může nastat problém s čitelností příliš dlouhých výpisů kvůli omezení pohybu ve výpisech. Všechny příkazy byly spouštěny v adresáři "bin"~uvnitř kořenového adresáře projektu "ycsb-0.17.0".
	
	V první části testování spustíme příkaz "ycsb~load"~pro připojení k databázi a vložení dat do databáze. Nejprve musíme specifikovat název testovaného DBS a následně zvolený Workload~\cite{workloads}~(viz popis YCSB Workloads~\ref{lab-workloads}). Pomocí volitelných parametrů~\cite{ycsb-properties} na konci každého příkazu specifikujeme naše požadavky. Například počet záznamů, které chceme do databáze vložit, je určen parametrem "-p~recordcount=NUM", počet vláken parametrem "-p~threadcount=NUM", a nejčastěji IP adresa nebo port DBS příkazy "-p~DBS\_NAME.host=IP\_ADR~-p~DBS\_NAME.port=NUM"~pro spojení s DBS. Pomocí zadání vlastnosti "-s"~po názvu DBS dosáhneme podrobnějšího výstupu při testování včetně chybových hlášek a logů. Celý příkaz pro vložení dat do DBS pak vypadá takto: "ycsb~load~DBS\_NAME~-s~-P~WORKLOAD~[-p~PARAMETERS]". Po dokončení vkládání dat získáme kromě dat v databázi také textový výstup popisující průběh zápisu dat do databáze, kde je zahrnuta propustnost vkládání a čas latence operací rozdělený do sekcí minimum, průměr, maximum a percentily, konkrétně 95. a 99. percentil.
	
	Druhá část testování se věnuje spuštění operací pro čtení a úpravu vložených dat z předchozího kroku pomocí příkazu "ycsb~run". Opět musíme zadat název testovaného DBS a Workload~\cite{workloads}, který nám určuje poměr operací pro čtení a úpravy dat. Pomocí volitelných parametrů~\cite{ycsb-properties} určíme počet prováděných operací "-p operationcount=NUM". Kombinace celkového počtu operací a Workloadu nám určí konkrétní počet operací čtení a úprav, které se během testu vykonají. Pokud pracujeme s Workloady D nebo E~(viz popis YCSB Workloads~\ref{lab-workloads}), dochází navíc k zápisu nových hodnot do DBS a počet klíčů v DBS stoupá. Ostatní vytížení provádějí pouze úpravy již existujících hodnot, a počet klíčů v DBS zůstává během testu stále stejný. Stejným způsobem jako v první fázi testování, i nyní můžeme specifikovat IP adresu a port DBS, případně počet vláken, podrobnější výstup testu atd. Celý příkaz pro spuštění testu DBS pak vypadá takto: "ycsb~run~DBS\_NAME~-s~-P~WORKLOAD~[-p~PARAMETERS]". Po dokončení testu získáme opět textový výstup v podobě tabulky popisující průběh testu, kde je zahrnuta propustnost operací a čas latence operací rozdělený do sekcí minimum, průměr, maximum a percentily, konkrétně 95. a 99. percentil.
	
	Před reálným testováním můžeme ověřit, zda je všechno správně nastavené, pomocí rychlého dema (viz příkazy~\ref{itemize-demo}). Demo se skládá ze dvou příkazů, naplnění databáze tisíci záznamy a následného otestování, provedení přibližně 500 operací čtení a 500 úprav v databázi BasicDB~\cite{basicdb}. Po spuštění obou příkazů by nám měly testy na konci vrátit status "Return=OK".
	
	\begin{itemize}\label{itemize-demo}
		\item .$\backslash$ycsb load basic -P ..$\backslash$workloads$\backslash$workloada
		\item .$\backslash$ycsb run basic -P ..$\backslash$workloads$\backslash$workloada
	\end{itemize}
	
	Pro názorný příklad si popíšeme a ukážeme příkazy pro testování databáze Redis~\cite{redis} (viz příkazy~\ref{itemiza-docker-ycsb} a obrázky~\ref{ps-docker},~\ref{ps-ycsb-load},~\ref{ps-ycsb-run}). Testovaným scénářem bude Workload A~\cite{workloads} (50\% Read, 50\% Update), který poběží na 4 vláknech. Do databáze se vloží 10~000 záznamů, a provede se 10~000 operací během testování (přibližně 5~000 čtení a 5~000 aktualizací dat). Nejprve si stáhneme Docker Image pro KDBS Redis příkazem "docker~pull"~a následně spustíme kontejner příkazem "docker~run"~a nastavíme porty. Nyní máme KDBS Redis připravenou a můžeme začít s testováním. Nejprve spustíme příkaz "ycsb~load"~k vložení dat do databáze. Po dokončení vkládání dat můžeme v příkazovém řádku vidět tabulku popisující informace o vkládání dat do databáze. Následně zahájíme testy spuštěním příkazu "ycsb~run", a opět uvidíme ve výstupní tabulce výpis informací o našem testu. Pokud na konci tabulky uvidíme status "Return=OK", vše proběhlo podle očekávání.
	
	\begin{itemize}\label{itemiza-docker-ycsb}
		\item docker pull redis:latest
		\item docker run --name my-redis -p 6379:6379 -d redis:latest
		\item .$\backslash$ycsb load redis -P  ..$\backslash$workloads$\backslash$workloada -p redis.host=127.0.0.1 -p redis.port=6379 \\-p recordcount=10000 -p threadcount=4
		\item .$\backslash$ycsb run redis -P ..$\backslash$workloads$\backslash$workloada -p redis.host=127.0.0.1 -p redis.port=6379 \\-p operationcount=10000 -p threadcount=4
		\item docker stop aba5fabc123example4568aa97
		\item docker rm aba5fabc123example4568aa97
	\end{itemize}
	
	\lstdefinestyle{DOS}
	{
		backgroundcolor=\color[RGB]{1, 36, 86},
		basicstyle=\scriptsize\color{white}\ttfamily
	}
	
	\begin{figure}
	\centering
	\begin{lstlisting}[style=DOS]
	PS E:\ycsb-0.17.0\bin> docker pull redis:latest
	latest: Pulling from library/redis
	Digest: sha256:f14f42fabc123example456c7e824b9
	Status: Image is up to date for redis:latest
	docker.io/library/redis:latest
		
	PS E:\ycsb-0.17.0\bin> docker run --name my-redis -p 6379:6379 -d redis:latest
	aba5fabc123example4568aa97
		
	PS E:\ycsb-0.17.0\bin> docker stop aba5fabc123example4568aa97
	aba5fabc123example4568aa97
		
	PS E:\ycsb-0.17.0\bin> docker rm aba5fabc123example4568aa97
	aba5fabc123example4568aa97
	\end{lstlisting}
	\caption{Docker Redis, příkazy pro stažení, spuštění, zastavení a odstranění DBS
	\label{ps-docker}}
	\end{figure}
	
	\begin{figure}
	\centering
	\begin{lstlisting}[style=DOS]
	PS E:\ycsb-0.17.0\bin> .\ycsb load redis -P ..\workloads\workloada
		-p redis.host=127.0.0.1 -p redis.port=6379 -p recordcount=10000
		-p threadcount=4
	YCSB Client 0.17.0
	Loading workload...
	Starting test.
	[OVERALL], RunTime(ms), 4211
	[OVERALL], Throughput(ops/sec), 2374.7328425552128
	[TOTAL_GCS_PS_Scavenge], Count, 4
	[TOTAL_GC_TIME_PS_Scavenge], Time(ms), 6
	[TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.14248397055331277
	[TOTAL_GCS_PS_MarkSweep], Count, 0
	[TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 0
	[TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0
	[TOTAL_GCs], Count, 4
	[TOTAL_GC_TIME], Time(ms), 6
	[TOTAL_GC_TIME_%], Time(%), 0.14248397055331277
	[CLEANUP], Operations, 4
	[CLEANUP], AverageLatency(us), 333.25
	[CLEANUP], MinLatency(us), 80
	[CLEANUP], MaxLatency(us), 1060
	[CLEANUP], 95thPercentileLatency(us), 1060
	[CLEANUP], 99thPercentileLatency(us), 1060
	[INSERT], Operations, 10000
	[INSERT], AverageLatency(us), 1647.61
	[INSERT], MinLatency(us), 904
	[INSERT], MaxLatency(us), 13895
	[INSERT], 95thPercentileLatency(us), 2481
	[INSERT], 99thPercentileLatency(us), 3389
	[INSERT], Return=OK, 10000
	\end{lstlisting}
	\caption{YCSB Redis, příkaz pro vložení dat (load)
	\label{ps-ycsb-load}}
	\end{figure}

	\begin{figure}
	\centering
	\begin{lstlisting}[style=DOS]
	PS E:\ycsb-0.17.0\bin> .\ycsb run redis -P ..\workloads\workloada
		-p redis.host=127.0.0.1 -p redis.port=6379 -p operationcount=10000
		-p threadcount=4
	YCSB Client 0.17.0
	Loading workload...
	Starting test.
	[OVERALL], RunTime(ms), 2560
	[OVERALL], Throughput(ops/sec), 3906.25
	[TOTAL_GCS_PS_Scavenge], Count, 1
	[TOTAL_GC_TIME_PS_Scavenge], Time(ms), 1
	[TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.0390625
	[TOTAL_GCS_PS_MarkSweep], Count, 0
	[TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 0
	[TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0
	[TOTAL_GCs], Count, 1
	[TOTAL_GC_TIME], Time(ms), 1
	[TOTAL_GC_TIME_%], Time(%), 0.0390625
	[READ], Operations, 5157
	[READ], AverageLatency(us), 998.8885010665116
	[READ], MinLatency(us), 389
	[READ], MaxLatency(us), 17695
	[READ], 95thPercentileLatency(us), 1692
	[READ], 99thPercentileLatency(us), 3479
	[READ], Return=OK, 5157
	[CLEANUP], Operations, 4
	[CLEANUP], AverageLatency(us), 221.75
	[CLEANUP], MinLatency(us), 60
	[CLEANUP], MaxLatency(us), 638
	[CLEANUP], 95thPercentileLatency(us), 638
	[CLEANUP], 99thPercentileLatency(us), 638
	[UPDATE], Operations, 4843
	[UPDATE], AverageLatency(us), 985.7646087136072
	[UPDATE], MinLatency(us), 364
	[UPDATE], MaxLatency(us), 17567
	[UPDATE], 95thPercentileLatency(us), 1744
	[UPDATE], 99thPercentileLatency(us), 3675
	[UPDATE], Return=OK, 4843
	\end{lstlisting}
	\caption{YCSB Redis, příkaz pro spuštění testů (run)
	\label{ps-ycsb-run}}
	\end{figure}

	\section{Vyhodnocení výsledků testů}
	
	Po opětovném spuštění stejných testů a následném zprůměrování naměřených hodnot jsme dospěli k finálním výsledkům. Hlavními měřenými parametry byly propustnost (počet operací za sekundu), celkový čas testu (v milisekundách) a minimální, průměrná a maximální latence operací (v mikrosekundách), spolu s percentily latence (v mikrosekundách), konkrétně 95. a 99. percentil.
	
	Veškeré hodnoty z testů byly zaznamenány do Excel dokumentu~\cite{excel} "KDBS\_Vysledky\_testu.xlsx". Tento dokument je součástí dodaných příloh k diplomové práci. Dokument je rozdělen do šesti sekcí. První 2 listy se zaměřují na konečné zprůměrované výsledky všech měření pro 4 testované scénáře. Zbývající 4 listy se věnují konkrétním výsledkům dílčích testů pro každou ze 4 testovaných KDBS, na základě kterých se počítaly výsledné hodnoty pro předešlé listy.
	
	Jednotlivé testy byly rozděleny do čtyř scénářů: Workload A, Workload B, Workload C a Insert only (viz~\ref{lab-workloads}). Pro každý scénář byly všechny čtyři vybrané KDBS testovány třikrát, a jejich výsledky byly následně zprůměrovány. U scénářů Workload A a Workload B byla měřena latence čtení a aktualizace dat zvlášť, a jejich výsledná latence byla počítána jako průměr latence pro čtení a úpravu dat. Workload C provádí pouze čtení dat, a proto nebylo zapotřebí průměrovat výsledné latence. Stejně tak tomu bylo u scénáře Insert only, kde dochází pouze k vkládání dat do KDBS. U grafů a tabulek latence je minimum označeno zkratkou "min", maximum "max"~a průměr "avg".
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Propustnost (kops/sec)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				%ymax=5.5,
				xtick=data,
				enlarge x limits=0.2,
				symbolic x coords={Workload A, Workload B, Workload C, Insert only},
				%restrict y to domain*=0:6, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%	\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis %cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(Workload A,4.8) (Workload B,4.726958) (Workload C,4.8683) (Insert only,2.553)};
				\addplot coordinates {(Workload A,5.081) (Workload B,4.9454377) (Workload C,4.77812) (Insert only,4.95306)};
				\addplot coordinates {(Workload A,4.1087) (Workload B,3.863588) (Workload C,4.51767) (Insert only,3.93796)};
				\addplot coordinates {(Workload A,1.2839777) (Workload B,1.77815) (Workload C,1.7833) (Insert only,1.0524)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A, B, C + Insert only - Propustnost (kops/sec)}
		\label{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Čas běhu (s)},
				legend style={at={(0.5,-0.2)}, anchor=north, legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%y=1.5cm, % změněno
				ymin=0,
				axis on top,
				%ymax=500, % změněno
				xtick=data,
				enlarge x limits=0.2,
				symbolic x coords={Workload A, Workload B, Workload C, Insert only},
				%restrict y to domain*=0:6, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%    \draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				nodes near coords style={font=\footnotesize, rotate=30, xshift=0.1cm, yshift=0.1cm}, % změněno na north
				%nodes near coords align={left}, % posunuto pouze doleva
				axis lines*=left,
				clip=false,
				]
				\addplot coordinates {(Workload A,208.4) (Workload B,212.0) (Workload C,205.5) (Insert only,39.19)};
				\addplot coordinates {(Workload A,196.8) (Workload B,202.3) (Workload C,209.5) (Insert only,20.21)};
				\addplot coordinates {(Workload A,243.4) (Workload B,263.2) (Workload C,221.4) (Insert only,25.41)};
				\addplot coordinates {(Workload A,803.9) (Workload B,562.8) (Workload C,562.0) (Insert only,69.75)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A, B, C + Insert only - Čas běhu (s)}
		\label{graph_Workloads A, B, C + Insert only - Runtime(s)}
	\end{figure}
	
	\subsection{Testový scénář 1 - Workload A}
	
	Prvním testovaným scénářem byl Workload A~\cite{workloads}, který se skládá z~50~\% operací pro čtení a~50~\% pro aktualizaci dat. Tento scénář byl vybrán pro demonstraci chování databází při vysokém počtu operací zaměřených na úpravu dat. Do každé KDBS bylo předem vloženo 100~000 záznamů a provádělo se 1~000~000 testovacích operací, tedy přibližně 500~000 čtení a 500~000 aktualizací. Konkrétní počet operací se vždy liší v řádu nízkých stovek, ale v součtu je vždy roven milionu.
	
	Z naměřených hodnot (viz tabulka~\ref{tab_workload_a} a grafy~\ref{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)},~\ref{graph_Workloads A, B, C + Insert only - Runtime(s)}) je patrné, že databáze Aerospike dosáhla nejvyšší propustnosti ze všech měřených KDBS s 5081,13~operacemi za sekundu a průměrnou dobou testu 196,8~sekund. Databáze Redis se umístila hned jako druhá s propustností~4801,04 operací za sekundu. Propustnost KDBS Redis je průměrně menší o~5,51~\% oproti KDBS Aerospike pro scénář Workload A. Následuje KDBS Memcached s propustností~4108,70 operací za sekundu, která zaostává o~19,13~\% oproti KDBS Aerospike a o~14,42~\% oproti KDBS Redis. Nakonec KDBS Riak KV dosáhla nejnižší propustnosti~1283,98~operací za sekundu, což je zhoršení o~74,73~\% oproti KDBS Aerospike. Riak KV je pro tento scénář téměř čtyřnásobně pomalejší ve srovnání s nejrychlejší měřenou databází Aerospike.
	
	Při porovnání latence operací na první pohled je patrné, že trend rychlostí latence operací kopíruje propustnosti. Pokud se zaměříme na minimální a průměrnou latenci (viz graf~\ref{graph_Workload A - Min Avg Latency (ms)}), tak vidíme, že KDBS Aerospike zpracovala operaci nejrychleji za~317~$\mu$s a KDBS Redis za~315,17~$\mu$s. Rozdíl v minimální latenci pro tyto dvě KDBS je zanedbatelný. Databáze Memcached má poté minimální latenci operace~401,5~$\mu$s, což je přibližně o~27~\% více než KDBS Aerospike a Redis. Databáze Riak KV má nejnižší latenci~1694~$\mu$s, což je pětinásobně více než nejnižší latence v tomto měření. Minimální latence KDBS Riak KV převyšuje i průměrné latence a 95. percentily tří zbylých databází ve všech testech pro tento scénář. Z toho měření vyplývá, že pro tento scénář a konfiguraci má KDBS Riak KV několikanásobně vyšší latenci operací. U průměrné latence vidíme, že KDBS Aerospike a Redis dosahují podobných hodnot přibližně~800~$\mu$s. KDBS Memcached dosahuje průměrné latence~967,9~$\mu$s, což je opět o~23,31~\% pomalejší ve srovnání s KDBS Aerospike.
	
	Z největších naměřených latencí (viz graf~\ref{graph_Workloads A, B, C + Insert only - Max Latency (ms)}) lze vidět, že KDBS Aerospike provedla nejpomalejší operaci za~28,53~ms. V nejhorším možném případě pro tento scénář z hlediska latence operací byla KDBS Aerospike rychlejší přibližně o~67,94~\% oproti KDBS Redis, u které maximální latence činí~47,92~ms, a přibližně o~190~\% při porovnání s KDBS Memcached, kde byla maximální latence~82,71~\%. KDBS Riak KV dosáhla nejvyšší latence~163,02~ms a je skoro dvojnásobně pomalejší při porovnání v rámci tohoto měření s druhou nejpomalejší KDBS Memcached.
	
	Pokud se zaměříme na 95. a 99. percentil latence (viz graf~\ref{graph_Workload A - Percentile Latency (ms)}), je zřejmé, že KDBS Aerospike dominuje svou nízkou latencí i v této kategorii pro scénář Workload A. KDBS Aerospike má 95. percentil s latencí~1121,8~$\mu$s, což je o~11,81~\% méně než 95. percentil KDBS Redis, který činí~1273~$\mu$s, a o~19,42~\% méně než KDBS Memcached, kde 95. percentil latence dosahuje hodnoty~1386,33~$\mu$s. Nakonec KDBS Riak KV dosáhla 95. percentilu latence~6757~$\mu$s. Hodnota pro 99. percentil latence KDBS Aerospike byla~1539,33~$\mu$s, což je opět nejnižší 99. percentil latence napříč všemi KDBS v rámci tohoto scénáře. Databáze Memcached má druhý nejnižší 99. percentil latence s hodnotou~1848,33~$\mu$s, a těsně za ní následuje KDBS Redis s 99. percentilem latence~1904,5~$\mu$s. KDBS Aerospike má 99. percentil nižší o~16,76~\% při srovnání s KDBS Memcached a o~18,95~\% menší při srovnání s KDBS Redis. KDBS Riak KV má opět nejhorší výsledky, a to latenci~11865,67~$\mu$s pro 99. percentil.
	
	Z naměřených hodnot testového scénáře Workload A lze vidět, že KDBS Aerospike zvládá nejlépe velký počet aktualizací ve srovnání s ostatními testovanými KDBS. Databáze Aerospike dosahovala výsledků přibližně o~15~\% lepších při srovnání s ostatními KDBS. Za ní následovaly KDBS Redis a Memcached, které měly vzájemně podobné výsledky. Databáze Redis byla v řádu jednotek procent lepší oproti Memcached ve všech měřeních s výjimkou 99. percentilu latence, kde byla KDBS Memcached lepší o~3,04~\% (viz graf~\ref{graph_Workload A - Percentile Latency (ms)}). Jediná databáze Riak KV několikanásobně zaostávala vůči všem ostatním testovaným KDBS v rámci všech naměřených hodnot. Pokud bychom se zaměřili zvlášť na operace čtení a aktualizací u KDBS Riak KV (viz tabulka~\ref{tab_workload_a}), uvidíme, že latence aktualizací je minimálně dvojnásobně horší než latence čtení pro tuto KDBS. Oproti tomu ostatní testované KDBS v rámci tohoto scénáře dosahovaly téměř identické latence jak pro čtení, tak zápis.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l l l l }
			\toprule
			KDBS & Redis & Riak KV & Aerospike & Memcached \\
			\midrule
			Čas běhu (ms) & 208419 & 803880,33 & 196849,33 & 243409,33 \\
			Propustnost (op/sec) & 4801,04 & 1283,98 & 5081,13 & 4108,70 \\
			\midrule
			\multicolumn{5}{l}{Čtení} \\
			Počet operací & 500157 & 500382 & 499106 & 500683 \\
			Avg letence ($\mu$s) & 836,77 & 2175,86 & 785,86 & 967,90 \\
			Min letence ($\mu$s) & 325,33 & 861,33 & 319,67 & 395,33 \\
			Max letence ($\mu$s) & 50473,67 & 158271 & 27311 & 83177,67 \\
			Letence 95. percentil ($\mu$s) & 1281,33 & 3695 & 1122,67 & 1385 \\
			Letence 99. percentil ($\mu$s) & 1917,33 & 7399 & 1540,33 & 1846 \\
			\midrule
			\multicolumn{5}{l}{Aktualizace} \\
			Počet operací & 499843 & 499618 & 500894 & 499317 \\
			Avg letence ($\mu$s) & 824,13 & 5941,33 & 782,68 & 967,90 \\
			Min letence ($\mu$s) & 305 & 2526,67 & 314,33 & 407,67 \\
			Max letence ($\mu$s) & 45375 & 167764,33 & 29753,67 & 82249,67 \\
			Letence 95. percentil ($\mu$s) & 1264,67 & 9819 & 1121 & 1387,67 \\
			Letencezva 99. percentil ($\mu$s) & 1891,67 & 16332,33 & 1538,33 & 1850,67 \\
			\midrule
			\multicolumn{5}{l}{Čtení + aktualizace} \\
			Počet operací & 1000000 & 1000000 & 1000000 & 1000000 \\
			Avg letence ($\mu$s) & 830,45 & 4058,59 & 784,27 & 967,90 \\
			Min letence ($\mu$s) & 315,17 & 1694 & 317 & 401,5 \\
			Max letence ($\mu$s) & 47924,3 & 163017,67 & 28532,33 & 82713,67 \\
			Letence 95. percentil ($\mu$s) & 1273 & 6757 & 1121,83 & 1386,33 \\
			Latence 99. percentil ($\mu$s) & 1904,5 & 11865,67 & 1539,33 & 1848,33 \\
			\bottomrule
		\end{tabular}
		\caption{Naměřené výsledky testů pro Workload A\label{tab_workload_a}}
	\end{table}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Latence (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=7pt,
				bar width=17pt,
				x=4cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				ymax=170,
				xtick=data,
				enlarge x limits=0.2,
				symbolic x coords={Workload A, Workload B, Workload C, Insert only},
				restrict y to domain*=0:190, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(Workload A,47.92) (Workload B,46.00) (Workload C,33.94) (Insert only,23.26)};
				\addplot coordinates {(Workload A,28.53) (Workload B,21.43) (Workload C,41.88) (Insert only,34.93)};
				\addplot coordinates {(Workload A,82.71) (Workload B,101.82) (Workload C,39.07) (Insert only,70.64)};
				\addplot coordinates {(Workload A,163.02) (Workload B,118.79) (Workload C,83.90) (Insert only,325.89)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A, B, C + Insert only - Max Latence (ms)}
		\label{graph_Workloads A, B, C + Insert only - Max Latency (ms)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Latence (ms)},
				symbolic x coords={Min,Avg},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%xmin=0,
				%width=15cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				%ymax=200,
				xtick=data,
				%xmin=Min-15,
				%xtick distance=10,
				enlarge x limits=0.5,
				%restrict y to domain*=0:300, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%	\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false,
				%extra x ticks={Min, Avg, Max},
				%x tick style={xticklabel style={xshift=-20pt}}
				]
				\addplot coordinates {(Min,0.3151666667) (Avg,0.830447166)};
				\addplot coordinates {(Min,0.317) (Avg,0.7842715474)};
				\addplot coordinates {(Min,0.4015) (Avg,0.9679028534)};
				\addplot coordinates {(Min,1.694) (Avg,4.058593436)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A - Min Avg Latence (ms)}
		\label{graph_Workload A - Min Avg Latency (ms)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentil latence (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=2.5,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95.,99.},
				restrict y to domain*=0:3, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95.,1.273) (99.,1.9045)};
				\addplot coordinates {(95.,1.12183) (99.,1.5393)};
				\addplot coordinates {(95.,1.3863) (99.,1.8483)};
				\addplot coordinates {(95.,6.757) (99.,11.8656)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A - Percentil latence (ms)}
		\label{graph_Workload A - Percentile Latency (ms)}
	\end{figure}
	
	\subsection{Testový scénář 2 - Workload B}
	
	Druhým testovaným scénářem byl Workload B~\cite{workloads}. Tento scénář se snaží více realisticky simulovat reálný provoz databázového systému, kde převažuje čtení záznamů a aktualizace jsou méně časté. Tento scénář se skládá z~95~\% operací zaměřených na čtení a~5~\% aktualizací. Na rozdíl od prvního scénáře, kde byl poměr těchto dvou operací vyvážený~(50~\% čtení, 50~\% aktualizace), je tento scénář více přizpůsobený databázím, které mají rychlé čtení, a pomalé aktualizace zde nejsou tak zásadní. Provádělo se přibližně 950~000 operací čtení a 50~000 úprav, přičemž konkrétní počet operací se vždy lišil v řádu nízkých stovek, ale součet byl vždy roven milionu.
	
	Z naměřených hodnot (viz tabulka~\ref{tab_workload_b}) opět vyplývá, že se opakuje stejný trend propustnosti KDBS jako u prvního scénáře. Pokud se podíváme na grafy propustnosti a celkového času běhu testu (viz grafy~\ref{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)},~\ref{graph_Workloads A, B, C + Insert only - Runtime(s)}), zjistíme, že KDBS Aerospike opět dosáhla nejlepší propustnosti napříč všemi testovanými KDBS, která se rovná 4945,37~operací za sekundu, s průměrným časem běhu celého testu 202,3~sekund. KDBS Aerospike má o~4,62~\% lepší propustnost při porovnání s KDBS Redis, o~27,99~\% oproti KDBS Memcached a o~178,18~\% oproti KDBS Riak KV. Na druhém místě co se týče propustnosti je stejně jako v předešlém scénáři KDBS Redis s propustností 4726,96~operací za sekundu. Dále následuje KDBS Memcached s hodnotou propustnosti 3863,59~operací za sekundu a nakonec stejně jako v předešlém scénáři KDBS Riak KV s propustností 1778,16~operací za sekundu.
	
	Z grafu minimální a průměrné latence operace (viz graf~\ref{graph_Workload B - Min Avg Latency (ms)}) vyplývá, že KDBS Aerospike a Redis mají prakticky identické časy minimální latence operace, a to~327~$\mu$s, liší se pouze v desetinných hodnotách, což je zanedbatelný rozdíl. Následuje KDBS Memcached s nejmenší latencí~397,83~$\mu$s, zaostávající o~17,71~\%. Poslední je KDBS Riak KV s nejvyšší hodnotou minimální latence operace~1795,33~$\mu$s, což je pomalejší o~81,78~\%. Průměrné časy latence operací jsou pro KDBS Aerospike a Redis opět téměř identické, s hodnotou 807,98~$\mu$s pro Aerospike a~843,29~$\mu$s pro Redis. Následuje KDBS Memcached s hodnotou~1055,21~$\mu$s, která je o~30,60~\% větší než u KDBS Aerospike. Nakonec KDBS Riak KV dosáhla nejvyšší latence~3950,21~$\mu$s, což je o~388,95~\% více než u KDBS Aerospike.
	
	Nejvyšší hodnoty latence (viz graf~\ref{graph_Workloads A, B, C + Insert only - Max Latency (ms)}) ukazují v tomto případě výrazný nárůst pro KDBS Memcached~(101,82~ms) a naopak pokles pro KDBS Riak KV~(118,79~ms) ve srovnání se scénářem Workload A. Databáze Aerospike a Redis si udržují hodnoty velmi blízké předchozímu scénáři. To znamená, že KDBS Aerospike dosahuje maximální latence~21,43~ms, což je o~53,41~\% méně než u KDBS Redis, kde je maximální~latence~46~ms.
	
	Pokud se zaměříme na porovnání percentilů latencí (viz graf~\ref{graph_Workload B - Percentile Latency (ms)}), vidíme, že i 95. a 99. percentil latence následuje trend ostatních výsledků tohoto testovaného scénáře. KDBS Aerospike má 95. percentil latence roven~1192,83~$\mu$s. Tento percentil je nižší o~9,87~\% než u KDBS Redis, která má 95. percentil latence roven~1323,67~$\mu$s. Oproti KDBS Memcached, která má 95. percentil latence roven~1744~$\mu$s je KDBS Aerospike rychlejší o~31,61~\%. Při porovnání s KDBS Riak KV vidíme obrovský rozdíl, kdy 95. percentil latence činí~6067,67~$\mu$s, což je přibližně o~409~\% více než u KDBS Aerospike a o~247,98~\% více než u KDBS Memcached, která je v rámci tohoto scénáře druhá nejpomalejší. Při sledování 99. percentilu vidíme opět stejné poměry hodnot. Nejnižší hodnota u KDBS Aerospike činí~1767,83~$\mu$s, následuje Redis s~2237,83~$\mu$s a zhoršením o~26,60~\% oproti Aerospike. Poté Memcached s hodnotou~2838~$\mu$s. Nakonec Riak KV dosahuje nejvyššího 99. percentilu latence~10650,33~$\mu$s.
	
	Z tohoto měření vyplývá, že KDBS Memcached ve scénáři Workload B zaostává oproti databázím Aerospike a Redis. Ty si udržují podobné výsledky jako v předchozím scénáři, naměřené hodnoty jsou taktéž vzájemně srovnatelné ve všech testovaných kategoriích. Přestože Aerospike dosahuje lepších výsledků, rozdíl mezi nimi je zanedbatelný. Databáze Riak KV stále dosahuje řádově horších hodnot než ostatní testované KDBS, ale propustnost se v tomto scénáři zlepšila o~38,43~\% oproti předchozímu scénáři. Zbylé tři KDBS si vedly srovnatelně s předchozím scénářem. To naznačuje, že KDBS Riak KV zaostává zejména při aktualizacích, což vede k zvýšení propustnosti při sníženém počtu aktualizací. Na druhou stranu KDBS Memcached zaostává o~6,08~\% oproti předchozímu scénáři, protože nemá dostatečně rychlé čtení ve srovnání s KDBS Aerospike a Redis.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l l l l }
			\toprule
			KDBS & Redis & Riak KV & Aerospike & Memcached \\
			\midrule
			Čas běhu (ms) & 212026,33 & 562799,67 & 202264 & 263195,67 \\
			Propustnost (op/sec) & 4726,96 & 1778,16 & 4945,38 & 3863,59 \\
			\midrule
			\multicolumn{5}{l}{Čtení} \\
			Počet operací & 949836 & 949728 & 949706 & 950435 \\
			Avg letence ($\mu$s) & 845,22 & 2072,91 & 805,97 & 1046,18 \\
			Min letence ($\mu$s) & 313,67 & 825,33 & 313,33 & 389 \\
			Max letence ($\mu$s) & 50559 & 110356,33 & 25732,33 & 112020,33 \\
			Letence 95. percentil & 1325 & 3232,33 & 1188 & 1735,33 \\
			Letence 99. percentil ($\mu$s) & 2232,33 & 6805,67 & 1756 & 2813 \\
			\midrule
			\multicolumn{5}{l}{Aktualizace} \\
			Počet operací & 50164 & 50272 & 50294 & 49565 \\
			Avg letence ($\mu$s) & 841,3802758 & 5827,51 & 809,98 & 1064,24 \\
			Min letence ($\mu$s) & 342 & 2765,33 & 341,33 & 406,67 \\
			Max letence ($\mu$s) & 41449,67 & 127231 & 17132,33 & 91625,67 \\
			Letence 95. percentil & 1322,33 & 8903 & 1197,67 & 1752,67 \\
			Letence 99. percentil ($\mu$s) & 2243,33 & 14495 & 1779,67 & 2851 \\
			\midrule
			\multicolumn{5}{l}{Čtení + aktualizace} \\
			Počet operací & 1000000 & 1000000 & 1000000 & 1000000 \\
			Avg letence ($\mu$s) & 843,30 & 3950,21 & 807,97 & 1055,21 \\
			Min letence ($\mu$s) & 327,83 & 1795,33 & 327,33 & 397,83 \\
			Max letence ($\mu$s) & 46004,33 & 118793,67 & 21432,33 & 101823 \\
			Letence 95. percentil & 1323,67 & 6067,67 & 1192,83 & 1744 \\
			Letence 99. percentil ($\mu$s) & 2237,83 & 10650,33 & 1767,83 & 2832 \\
			\bottomrule
		\end{tabular}
		\caption{Naměřené výsledky testů pro Workload B\label{tab_workload_b}}
	\end{table}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Latence (ms)},
				symbolic x coords={Min,Avg},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%xmin=0,
				%width=15cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				%ymax=200,
				xtick=data,
				%xmin=Min-15,
				%xtick distance=10,
				enlarge x limits=0.5,
				%restrict y to domain*=0:300, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%	\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false,
				%extra x ticks={Min, Avg, Max},
				%x tick style={xticklabel style={xshift=-20pt}}
				]
				\addplot coordinates {(Min,0.33) (Avg,0.84)};
				\addplot coordinates {(Min,0.33) (Avg,0.81)};
				\addplot coordinates {(Min,0.40) (Avg,1.06)};
				\addplot coordinates {(Min,1.80) (Avg,3.95)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload B - Min Avg Latence (ms)}
		\label{graph_Workload B - Min Avg Latency (ms)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentil latence (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=3,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95.,99.},
				restrict y to domain*=0:3.5, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95.,1.3236) (99.,2.237833)};
				\addplot coordinates {(95.,1.19283) (99.,1.76783)};
				\addplot coordinates {(95.,1.744) (99.,2.832)};
				\addplot coordinates {(95.,6.06766) (99.,10.65033)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload B - Percentil latence (ms)}
		\label{graph_Workload B - Percentile Latency (ms)}
	\end{figure}
	
	\subsection{Testový scénář 3 - Workload C}
	
	Třetím testovým scénářem je Workload C~\cite{workloads}. Tento scénář se věnuje čistě čtení záznamů. Výsledky tohoto scénáře nám pomohou porovnat propustnost testovaných KDBS čistě na základě načítání hodnot. Pokud má databáze velice rychlé čtení ale pomalé zápisy, aktualizace nebo mazání hodnot, tak v tomto scénáři bude excelovat. Testovalo se vždy 1~000~000 operací čtení hodnot.
	
	Naměřené hodnoty (viz tabulka~\ref{tab_workload_c}) nám ukazují navýšení propustnosti KDBS Redis oproti předešlým scénářům. Propustnost pro tuto KDBS stoupla na 4868,3~operací za sekundu, což je nejvyšší propustnost napříč ostatními testovanými databázemi (viz graf~\ref{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)}), testy na KDBS Redis pro tento scénář trvaly průměrně 205,5~sekund (viz graf~\ref{graph_Workloads A, B, C + Insert only - Runtime(s)}). Na druhém místě je KDBS Aerospike s propustností 4778,13~operací za sekundu, což je o 86,87~operací za sekundu méně a přibližně o~1,85~\% v porovnání s KDBS Redis. Následuje KDBS Memcached s propustností 4517,67~operací za sekundu a poklesem o 350,63~operací za sekundu, což je~7,2~\% oproti KDBS Aerospike. Nakonec KDBS Riak KV zde dosáhla stejné propustnosti jako v předešlém scénáři Workload B a to 1783,39~operací za sekundu. Propustnost KDBS Riak KV je při porovnání s KDBS Aerospike menší o 3084,91~operací za sekundu a~63,39~\%.
	
	Pokud se podíváme na graf minimální a průměrné latence (viz graf~\ref{graph_Workload C - Min Avg Latency (ms)}), můžeme vidět, že KDBS Redis měla nejmenší minimální latenci napříč ostatními testovanými KDBS a to~308,67~$\mu$s. Hned za ní následuje KDBS Aerospike s latencí~319,33~$\mu$s a nárůstem o~3,45~\%. Následuje KDBS Memcached s minimální latencí~376~$\mu$s a nárůstem přibližně o~21,8~\% v porovnání s KDBS Redis. Na posledním místě je opět KDBS Riak KV s minimální latencí~804,67~$\mu$s, což je tentokrát menší než jsou průměrné latence ostatních testovaných KDBS. Toto měření nám dokazuje dobré výsledky pro čtení dat u KDBS Riak KV oproti aktualizacím prováděným touto databází. Oproti KDBS Redis je zde ale stále nárůst o~160,73~\%, což je ale stále méně než u předchozích scénářů. U průměrné latence odezvy pozorujeme stejný trend jako u minimálních hodnot. Databáze Redis vede s nejmenší průměrnou latencí~819,32~$\mu$s. Hned za ní následují KDBS Aerospike s latencí~835,17~$\mu$s a nárůstem o~1,93~\% a Memcached s latencí~880,17~$\mu$s a nárůstem o~7,43~\%. Nakonec je zde opět KDBS Riak KV s průměrnou latencí~2241,01~$\mu$s a nárůstem o~173,54~\% oproti KDBS Redis, nicméně stále je tento nárůst menší než u předchozích scénářů, kde byl i čtyřnásobný.
	
	Maximální latence (viz graf~\ref{graph_Workloads A, B, C + Insert only - Max Latency (ms)}) nám ukazují, že KDBS Redis je nejvíce stabilní při všech dotazech s maximální latencí nejpomalejší operace~33,94~ms. Následují databáze Memcached s latencí~39,07~ms a nárůstem o~15,11~\% a Aerospike s maximální latencí~41,88~ms a nárůstem o~23,39~\%. Na posledním místě je zde KDBS Riak KV s maximální latencí~83,9~ms, což je nárůst o~147,27~\% při porovnání s KDBS Redis, každopádně při porovnání s prvním scénářem došlo k poklesu o~48,51~\% z maximální latence~163,02~ms a při porovnání s druhým scénářem k poklesu o~29,35~\% z latence~118,79~ms.
	
	Hodnoty percentilů (viz graf~\ref{graph_Workload C - Percentile Latency (ms)}) nám pro 95. percentil opět ukazují nejnižší latenci pro KDBS Redis a to~1213,33~$\mu$s. Následuje KDBS Memcached s latencí~1233,33~$\mu$s a nárůstem pouze o~1,65~\% ve srovnání s KDBS Redis. Další je KDBS Aerospike s latencí~1242,33~$\mu$s a nárůstem o~2,39~\%. Na konci je poslední KDBS Riak s latencí~3717,33~$\mu$s a nárůstem o~206,15~\% při porovnání s KDBS Redis. Tento 95. percentil nám ukazuje zanedbatelný rozdíl latence mezi databázemi Redis, Memcached a Riak. Jediná KDBS Riak KV zde měla několikanásobně vyšší latenci. U 99. percentilu můžeme poprvé vidět nejlepší výsledky u KDBS Memcached, její letence je~1615,33~$\mu$s, což je znatelně menší oproti ostatním KDBS v této kategorii. Následují databáze Redis s latencí~1856~$\mu$s a nárůstem o~14,91~\% a Aerospike s latencí~1861,67~$\mu$s a nárůstem o~15,25~\%. Procentuální rozdíl 99. percentilu latence mezi KDBS Aerospike a Redis je zanedbatelný a činí pouze~0,305~\%. Na posledním místě je opět KDBS Riak KV s latencí~7885,67~$\mu$s a nárůstem o~388,15~\% při porovnání s KDBS Memcached a~323,41~\% při porovnání s KDBS Aerospike.
	
	Tento scénář ukázal dominanci KDBS Redis při operacích zaměřených čistě na čtení. Při porovnání propustnosti prvním scénářem (viz graf~\ref{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)}) byla tato KDBS lepší přibližně o~67,3~operací za sekundu a o~141,34~operací za sekundu oproti druhému scénáři. Každopádně KDBS Aerospike a Memcached si opět vedly velice obstojně a zaostávaly pouze o desítky procent. Databáze Riak KV dokázala, že při čistém čtení si vede stejně dobře, jako když se ke čtení provádělo navíc~5~\% aktualizací v druhém scénáři. Při porovnání této KDBS s prvním scénářem byl nárůst propustnosti o~499,41~operací za sekundu, tedy o~38,86~\%.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l l l l }
			\toprule
			KDBS & Redis & Riak KV & Aerospike & Memcached \\
			\midrule
			Čas běhu (ms) & 205492,67 & 562029,33 & 209528 & 221353,33 \\
			Propustnost (op/sec) & 4868,30 & 1783,39 & 4778,13 & 4517,67 \\
			\midrule
			\multicolumn{5}{l}{Čtení} \\
			Počet operací & 1000000 & 1000000 & 1000000 & 1000000 \\
			Avg letence ($\mu$s) & 819,32 & 2241,01 & 835,17 & 880,17 \\
			Min letence ($\mu$s) & 308,69 & 804,67 & 319,33 & 376 \\
			Max letence ($\mu$s) & 33935 & 83903 & 41881,67 & 39071 \\
			Letence 95. percentil ($\mu$s) & 1213,33 & 3714,33 & 1242,33 & 1233,33 \\
			Letence 99. percentil ($\mu$s) & 1856 & 7885,67 & 1861,67 & 1615,33 \\
			\bottomrule
		\end{tabular}
		\caption{Naměřené výsledky testů pro Workload C\label{tab_workload_c}}
	\end{table}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Latence (ms)},
				symbolic x coords={Min,Avg},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%xmin=0,
				%width=15cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				%ymax=200,
				xtick=data,
				%xmin=Min-15,
				%xtick distance=10,
				enlarge x limits=0.5,
				%restrict y to domain*=0:300, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%	\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false,
				%extra x ticks={Min, Avg, Max},
				%x tick style={xticklabel style={xshift=-20pt}}
				]
				\addplot coordinates {(Min,0.31) (Avg,0.82)};
				\addplot coordinates {(Min,0.32) (Avg,0.84)};
				\addplot coordinates {(Min,0.38) (Avg,0.88)};
				\addplot coordinates {(Min,0.80) (Avg,2.24)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload C - Min Avg Latence (ms)}
		\label{graph_Workload C - Min Avg Latency (ms)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentil latence (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=4,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95.,99.},
				restrict y to domain*=0:4.5, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95.,1.21) (99.,1.856)};
				\addplot coordinates {(95.,1.24) (99.,1.8616)};
				\addplot coordinates {(95.,1.23) (99.,1.6153)};
				\addplot coordinates {(95.,3.71) (99.,7.8856)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload C - Percentil latence (ms)}
		\label{graph_Workload C - Percentile Latency (ms)}
	\end{figure}
	
	\subsection{Testový scénář 4 - Insert only} 
	
	Poslední testový scénář, Insert only s číslem 4, se věnoval pouze vkládání dat do KDBS. Všechny předchozí scénáře se zaměřovaly na čtení nebo aktualizace. Databáze u předešlých scénářů se však neplnila novými daty, vždy obsahovala 1~000~000 záznamů. Tentokrát byla každá databáze nově vytvořena a před spuštěním testu byla prázdná. Testovala se právě propustnost a odezva během plnění databáze novými daty. Do každé KDBS se vkládalo přesně 100~000 záznamů.
	
	Při zkoumání naměřených hodnot (viz tabulka~\ref{tab_workload_insert_only}) případně výšky sloupců v grafu (viz graf~\ref{graph_Workloads A, B, C + Insert only - Runtime(s)}), si můžeme všimnout poměrně kratšího času vkládání dat. Tento problém nastává především proto, že do databází bylo vkládáno desetkrát méně záznamů než je počet prováděných operací u předchozích scénářů. Proto vkládání dat zabralo pouze desítky sekund oproti ostatním testům, které trvaly stovky sekund. Proto by bylo vhodnější pro graf času běhu vytvořit spíše databáze obsahující 1~000~000 záznamů, nebo tuto kategorii vykreslovat zvlášť. Konkrétně se nejrychlejší KDBS Aerospike naplnila za 20,21 sekund. Nicméně ostatní porovnání jsou vzájemně relevantní a hodnoty propustností nebo latencí jsou přizpůsobeny pro porovnání napříč všemi scénáři. Při měření propustnosti pro 100~000 a 1~000~000 operací vkládání vycházely testy propustnosti a latence stejně. Navíc opětovým spuštěním testů a průměrováním výsledků se omezily možné zásadní odchylky.
	
	Pokud se podíváme na graf propustnosti (viz graf~\ref{graph_Workloads A, B, C + Insert only - Throughput (kiloops/sec)}), uvidíme velkou rychlost vkládání záznamů KDBS Aerospike oproti všem ostatním testovaným databázím. Propustnost této KDBS je~4953,06~operací za sekundu. S velkým skokem následuje KDBS Memcached s propustností 3937,96~operací za sekundu a poklesem o~20,5~\%. Za ní následuje KDBS Redis s propustností 2553,02~operací za sekundu a poklesem o~48,48~\% oproti KDBS Aerospike. Poslední je KDBS Riak KV s propustností 1052,43~operací za sekundu a poklesem o~78,79~\%.
	
	Z grafu minimální a průměrné latence (viz graf~\ref{graph_Insert only - Min Avg Latency (ms)}) vyčteme stejnou posloupnost nejrychlejších databází jako z grafu propustnosti. Databáze s nejnižší minimální latencí,~318,67~$\mu$s, je KDBS Aerospike. Opět následuje KDBS Memcached s latencí~406,33~$\mu$s a nárůstem o~27,5~\%. Za ní je KDBS Redis s minimální latencí~762~$\mu$s a nárůstem o~139,02~\% oproti KDBS Aerospike. Na posledním místě je KDBS Riak KV s latencí~1121,33~$\mu$s a nárůstem času nejnižší latence operace zápisu o~251,77~\%. Kategorie zaměřená na průměrné latence má také tento trend. První je KDBS Aerospike s latencí~800,58~$\mu$s. Následuje KDBS Memcached s latencí~983,52~$\mu$s a nárůstem o~22,83~\%. Na třetím místě je KDBS Redis s latencí~1559,62~$\mu$s a nárůstem průměrné latence o~94,75~\% oproti KDBS Aerospike. Na konci je KDBS Riak KV s latencí~2753,93~$\mu$s a nárůstem o~243,74~\%.
	
	Dle grafu maximální latence (viz graf~\ref{graph_Workloads A, B, C + Insert only - Max Latency (ms)}) soudíme, že KDBS Redis je sice v tomto scénáři třetí co se týče propustnosti a minimální i průměrné latence, každopádně znatelně dominuje maximální latenci zápisu oproti ostatním KDBS. Tato databáze má maximální latenci pouze~23,26~ms. Oproti tomu KDBS Aerospike má maximální latenci~34,93~ms a dochází zde k nárůstu latence o~50,22~\%. Následuje KDBS Memcached s maximální latencí~70,64~ms a nárůstem latence o~203,79~\% při porovnání s KDBS Redis. Poslední je KDBS Riak KV s naměřenou hodnotou maximální latence~325,89~ms, což je nárůst o~1300,73~\% a několikanásobně nejvyšší naměřená latence napříč testy všech databází ve všech čtyřech scénářích.
	
	V grafu znázorňujícím 95. a 99. percentil latence (viz graf~\ref{graph_Insert only - Percentile Latency (ms)}) vidíme stejný trend jako u propustnosti a minimální a průměrné latence v rámci tohoto scénáře. Pro 95. percentil latence má opět KDBS Aerospike nejnižší latenci s hodnotou~1199,33~$\mu$s. Za ní následuje KDBS Memcached s latencí~1536,67~$\mu$s a nárůstem o~28,12~\%. Další v pořadí je KDBS Redis s latencí~2219~$\mu$s a nárůstem 95. percentilu latence o~84,99~\% oproti KDBS Aerospike. Poslední je pro tento percentil KDBS Riak KV s 95. percentilem latence s hodnotou~4386,33~$\mu$s a nárůstem o~265,72~\%. Následně pak 99. percentil zastává stejné uspořádání KDBS dle nejnižších latencí jako 95. percentil. Databáze Aerospike má latenci~1690~$\mu$s, za ní je KDBS Memcached s latencí~2322,33~$\mu$s a nárůstem o~37,43~\%. Následuje KDBS Redis s latencí~3195~$\mu$s a nárůstem 99. percentilu latence o~89,05~\% oproti KDBS Aerospike. Na posledním místě je opět KDBS Riak KV s latencí~8124,33~$\mu$s a nárůstem o~380,57~\%.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l l l l }
			\toprule
			KDBS & Redis & Riak KV & Aerospike & Memcached \\
			\midrule
			Čas běhu (ms) & 39184 & 69749 & 20212 & 25412,67 \\
			Propustnost (op/sec) & 2553,02 & 1052,43 & 4953,06 & 3937,96 \\
			\midrule
			\multicolumn{5}{l}{Zápis} \\
			Počet operací & 100000 & 100000 & 100000 & 100000 \\
			AverageLatency(us) & 1559,62 & 2753,93 & 800,58 & 983,52 \\
			Min letence ($\mu$s) & 762 & 1121,33 & 318,67 & 406,33 \\
			Max letence ($\mu$s) & 23260,33 & 325887 & 34927 & 70644,33 \\
			Letence 95. percentil ($\mu$s) & 2219 & 4386,33 & 1199,33 & 1536,67 \\
			Letence 99. percentil ($\mu$s) & 3195 & 8124,33 & 1690 & 2322,33 \\
			\bottomrule
		\end{tabular}
		\caption{Naměřené výsledky testů pro Insert only\label{tab_workload_insert_only}}
	\end{table}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Latence (ms)},
				symbolic x coords={Min,Avg},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				%xmin=0,
				%width=15cm,
				%y=1.5cm,
				ymin=0,
				axis on top,
				%ymax=200,
				xtick=data,
				%xmin=Min-15,
				%xtick distance=10,
				enlarge x limits=0.5,
				%restrict y to domain*=0:300, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				%after end axis/.code={ % Draw line indicating break
					%	\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
					%},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false,
				%extra x ticks={Min, Avg, Max},
				%x tick style={xticklabel style={xshift=-20pt}}
				]
				\addplot coordinates {(Min,0.76) (Avg,1.56)};
				\addplot coordinates {(Min,0.32) (Avg,0.80)};
				\addplot coordinates {(Min,0.41) (Avg,0.98)};
				\addplot coordinates {(Min,1.12) (Avg,2.75)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Insert only - Min Avg Latence (ms)}
		\label{graph_Insert only - Min Avg Latency (ms)}
	\end{figure}
	
	\begin{figure}
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentil latence (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=5pt,
				bar width=15pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=4.5,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95.,99.},
				restrict y to domain*=0:5.1, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95.,2.219) (99.,3.195)};
				\addplot coordinates {(95.,1.11933) (99.,1.690)};
				\addplot coordinates {(95.,1.5366) (99.,2.32233)};
				\addplot coordinates {(95.,4.3863) (99.,8.12433)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Insert only - Percentil latence (ms)}
		\label{graph_Insert only - Percentile Latency (ms)}
	\end{figure}
	
	Tento scénář nám ukázal, jak rychlá dokáže být KDBS Aerospike, pokud jde o vkládání nových záznamů do databáze. S nejvyšší propustností 4953,06~operací za sekundu překonala všechny ostatní KDBS v rámci tohoto scénáře. Byla rychlejší o více než~1015~operací za sekundu ve srovnání s druhou nejrychlejší v tomto scénáři, KDBS Memcached. Samotná KDBS Memcached zde byla pro téměř všechny kategorie druhá nejrychlejší, zatímco v předchozích třech scénářích se pohybovala spíše až na třetím místě. Jediná kategorie ve které byla Memcached až třetí v rámci tohoto měření, byla maximální latence, kde zaostávala za databázemi Redis a Aerospike. Databáze Redis zde převážně obsadila pozici třetí nejrychlejší, přičemž v jediné kategorii nejvyšší naměřené latence dosáhla nejnižších hodnot napříč ostatními KDBS. Databáze Riak KV zůstala stále nejpomalejší a dosahovala ještě horší propustnosti než v předchozích scénářích. Oproti scénáři Workload C, kde dosáhla nejvyšší propustnosti 1783,39~operací za sekundu, v porovnání sama se sebou v rámci všech scénářů měla v tomto scénáři pokles o 730,97~operací za sekundu a~41,01~\%.
	
	\subsection{Porovnání výsledků testů}
	
	Obecně se dá říci, že v rámci těchto testů si průměrně vedla nejlépe KDBS Aerospike, následně za ní pak KDBS Redis a KDBS Memcached. Každopádně výsledky těchto tří KDBS jsou velice vyrovnané a liší se od konkrétních scénářů.
	
	DBS Aerospike měl kromě scénáře Workload C zaměřeného na čisté čtení vždy nejvyšší propustnost. Dosahovala nejlepších výsledků jak pro operace aktualizací, tak i zápisu. Za ní následovala KDBS Redis s nejrychlejším čtením záznamů a druhou nejrychlejší aktualizací. Tato KDBS zaostávala pouze při operaci vkládání nových záznamů. Databáze Memcached byla sice pomalejší pro čtení i aktualizace, ale při vkládání záznamů byla druhá nejrychlejší hned po KDBS Aerospike a podstatně rychlejší než KDBS Redis.
	
	V rámci všech testů KDBS Riak KV několikanásobně zaostávala vůči zbylým třem databázím. Při testování docházelo i k pádům samotné KDBS spouštěné v Dockeru~\cite{docker} a obecně k chybám a přetékání paměti, způsobené nejspíše špatným nastavením konfiguračních souborů. Obecně nastavení této KDBS bylo nejtěžší v porovnání s ostatními. Ve výsledcích testů (viz tabulka~\ref{tab_workload_a}) můžeme vidět, že KDBS Riak KV má hodnotu nejnižší latence stále vyšší než jsou průměrné latence zbylých tří databází a dokonce je i vyšší než 95. percentil latence zbylých KDBS.
	
	\subsection{Vizualizace do grafů}
	
	V grafech porovnávajících propustnosti KDBS byla zavedena jednotka "kops/sec", která reprezentuje tisíce provedených operací za sekundu. Všechny měřené propustnosti se pohybují v řádech jednotek tisíců operací za sekundu, a proto je tato jednotka vhodná a zlepšuje čitelnost grafů. Nejvyšší naměřené hodnoty latence byly zařazeny do jednoho společného grafu napříč všemi testovými scénáři (viz graf~\ref{graph_Workloads A, B, C + Insert only - Max Latency (ms)}), protože při porovnání maximální latence v jednom grafu daného scénáře s minimální a průměrnou latencí (viz graf~\ref{graph_Workload A - Min Avg Latency (ms)}) docházelo k velkému nepoměru vykreslených hodnot, což způsobovalo zanedbatelné vizuální rozdíly pro hodnoty nejnižší a průměrné. Při použití logaritmické stupnice nebyly grafy stále čitelné, proto jsou maximální latence vloženy do jednoho společného grafu. Pokud na sloupcovém grafu dochází k několikanásobnému převýšení jedné maximální hodnoty některého sloupce vůči sloupcům ostatním v rámci dané kategorie či celého grafu, tak je využit vizuální indikátor přetrhnutého sloupce (viz graf~\ref{graph_Workload B - Percentile Latency (ms)}), který znázorňuje, že daný sloupec má několikanásobně vyšší hodnotu oproti ostatním, a zároveň nedochází k vykreslení celé výšky sloupce, aby bylo možné zachovat vizuální poměry ostatních několikanásobně nižších hodnot.
	
	\chapter{Závěr\label{chapter:5-diploma_results}}
	
	V této diplomové práci bylo zkoumáno, co vlastně jsou KDBS, a byly představeny vlastnosti a využitelnost těchto databází. Na trhu dominují především RDBS, a tak bylo cílem práce osvětlit i část ze světa NoSQL databází. KDBS se často používají pro implementaci cache paměti a dle testů dokáží dosahovat úctyhodné propustnosti v řádu několika tisíců operací za sekundu. Sledováním aktuálních trendů bylo zjištěno, že obecně NoSQL DBS zažívají za poslední desetiletí velký nárůst popularity a dostávají se více do širokého povědomí~\cite{dbranking-trend-by-model}. Není ve snaze tvrdit, že by v budoucnu měly KDBS nahradit RDBS, ale KDBS se spíše stávají větší součástí databázových systémů a fungují společně s RDBS v souladu díky své horizontální škálovatelnosti a nedefinovanému schématu dat.
	
	Práce poskytla možnost nahlédnout do odvětví testování databází a z praktického hlediska konkrétně seznámila s testovacím prostředím YCSB~\cite{ycsb}. Ukázalo se, že toto prostředí je vhodné právě pro testy databází s párovými daty klíč-hodnota, a při správném nastavení je možné připravit veškeré testy na míru. Nicméně rozběhnutí prostředí YCSB a propojení s vybranými KDBS bylo jednou z největších výzev pro pokrok samotné práce. Několikrát bylo potřeba doinstalovat nový software nebo jeho kompatibilní verze, a nakonec i nastavit správné systémové proměnné.
	
	Práce ukázala, jak důležité je provádět testy databází pro možnost porovnání využití jednotlivých KDBS pro různé scénáře použití. Stejně tak se ukázalo, jak složité je komplexně otestovat KDBS a vzájemně je porovnávat. Existuje nespočet nastavení parametrů testů, a je zapotřebí vybrat ty nejvhodnější pro co nejširší škálu databází. Navíc každá z databází se může chovat odlišně při různých testech nad odlišnými daty. Bylo zjištěno, že testy musí být připraveny nezaujatě a vhodně pro všechny KDBS. Je totiž možné nachystat testy na míru pro určitou databázi, kde budou ostatní databáze zaostávat, a vybraná KDBS bude vypadat jako ideální ve všech ohledech. Stejně tak to lze udělat i naopak s ostatními KDBS. Proto je potřeba testovat objektivně, opakovaně a ideálně rozsáhle.
	
	Není tvrzeno, že je možné vybrat čistě jednu nejlepší KDBS, která by byla nejideálnější ve všech ohledech. Pokud by měly být stručně zhodnoceny testované KDBS, je nutné především vyzdvihnout KDBS Aerospike~\cite{aerospike}. Kromě jednoho scénáře zaměřeného na čisté čtení měla vždy nejvyšší propustnost. Dosahovala skvělých výsledků jak pro aktualizace záznamů, tak pro vkládání nových záznamů. Těsně za ní následovala KDBS Redis~\cite{redis} s nejrychlejším čtením záznamů a druhou nejrychlejší aktualizací. Tato KDBS zaostávala pouze při operaci vkládání nových záznamů. Databáze Memcached~\cite{memcached} byla sice pomalejší pro čtení i aktualizace, ale při vkládání záznamů byla druhá nejrychlejší hned po KDBS Aerospike a podstatně rychlejší než KDBS Redis. Na posledním místě se umístila KDBS Riak KV~\cite{riak}, nejspíše kvůli špatnému nastavení konfiguračních souborů. Ve všech testech byla podstatně horší než zbylé testované databáze. Tato KDBS měla i nejsložitější nastavení pro chod testů napříč všemi ostatními KDBS, a obecně s ní bylo nejvíce problémů. Stávalo se, že i během testů padala nebo vracela chyby.
	
	Při vytváření této práce se autor seznámil s řadou nových pojmů a systémů, ať už jde o práci s prostředím Docker~\cite{docker}, YCSB nebo konkrétně popisovanými databázemi. Z hlediska práce s testovacím prostředí YCSB a testování vybraných KDBS v něm, byla pro autora práce obohacující a naučná.
	
	\nocite{*}
	
	\printbibliography[title={Literatura}, heading=bibintoc]
	
\end{document}