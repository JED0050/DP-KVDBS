% !TeX spellcheck = cs_CZ
\documentclass[czech,master,dept460,male,csharp,cpdeclaration]{diploma}

\usepackage[autostyle=true,czech=quotes]{csquotes} % korektni sazba uvozovek, podpora pro balik biblatex
\usepackage[backend=bibtex, style=iso-numeric, alldates=iso]{biblatex} % bibliografie
\usepackage{dcolumn} % sloupce tabulky s ciselnymi hodnotami
\usepackage{subfig} % makra pro "podobrazky" a "podtabulky"
\usepackage{rotating}

\usepackage{geometry}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pgfplots}

%\usepackage{mathtools} %- blokuje list obrázků a tabulek

\ThesisAuthor{Bc. Jan Jedlička}

\ThesisSupervisor{prof. Ing. Michal Krátký, Ph.D.}

\CzechThesisTitle{Key-value databázové systémy}

\EnglishThesisTitle{Key-value database systems}

\SubmissionYear{2024}

\ThesisAssignmentFileName{ThesisSpecification_JED0050_vsboee2302B326.pdf}

\Acknowledgement{Na tomto místě bych chtěl poděkovat vedoucímu této práce prof. Ing. Michalovi Krátkému, Ph.D., za poskytnutí užitečných rad a pomoci vedením práce.}

\CzechAbstract{Cílem diplomové práce je popsat Key-value databázové systémy, ukázat výhody těchto systémů a představit jedny z jejich významných představitelů. Součástí práce je návrh a implementace testovacího prostředí pro testování těchto systémů s ostatními SŘBD. Práce je zakončena vyhodnocením výsledků testů vybraných databázových systémů.}

\CzechKeywords{NoSQL; Key-value databáze}

\EnglishAbstract{The aim of the diploma thesis is to describe Key-value database systems, to demonstrate the advantages of these systems, and to present some of their significant representatives. Part of the work involves designing and implementing a test environment for testing these systems alongside other DBMS. The thesis concludes with an evaluation of the test results from selected database systems.}

\EnglishKeywords{NoSQL; Key-value database}

\AddAcronym{NoSQL}{Not only Structured Query Language}
\AddAcronym{Key-value database}{Klíč-hodnota databáze}
\AddAcronym{KDBS}{Key-value database}
\AddAcronym{TTL}{Time to live}
\AddAcronym{YCSB}{Yahoo! Cloud Serving Benchmark}

\addbibresource{citace.bib}

\begin{document}
	
	\MakeTitlePages
	
	\listoffigures
	\listoftables
	
	\chapter{Úvod}
	
	Key-value (neboli Klíč-hodnota) databázové systémy~\cite{amaz-key-value-db, ytb-nosql-db}, dále jen zkráceně KDBS, jsou jedním z paradigmat pro úložiště dat. Databáze je navržena pro ukládání, načítání a správu různých dat, dnes známých jako slovníky nebo hashovací tabulky. Slovníky obsahují kolekci objektů či záznamů, které mohou opět obsahovat množinu různých polí s daty. Záznamy jsou do slovníků, či hashovacích tabulek, ukládány za pomoci klíče, který identifikuje pozici záznamu v datové struktuře a používá se k následnému vyhledávání dat v databázi.
	
	KDBS fungují odlišně oproti tradičním relačním databázovým systémům. Relační databáze mají předdefinovanou datovou strukturu v databázi jako sérii tabulek s dopředu definovanými datovými typy. Díky tomuto modelu může relační databázový systém provádět řadu optimalizací. Na druhou stranu KDBS mohou mít pro každý záznam různě definované kolekce dat s odlišnými velikostmi a počty atributů. Tato vlastnost nabízí KDBS flexibilitu a možnost přiblížení se k objektově orientovanému programování. Protože KDBS nevyžaduje pevně nastavené datové typy hodnot, jako je tomu u relační databáze, tak KDBS často potřebují méně paměti k uložení stejných dat, což může vést k značnému nárůstu výkonu. Dále tyto databáze bývají distribuované a dosahují horizontální až lineární škálovatelnosti.
	
	Výkon a nedostatečná standardizace omezovaly KDBS pouze na specializovaná využití, ale díky rychlému přechodu na cloud computing dochází v posledních letech k rozšíření obecné využitelnosti NoSQL databázových systémů. Například databázový systém Redis~\cite{redis} je v současnosti jedním z deseti nejlépe hodnocených~\cite{db-engineers-ranking} databázových systémů napříč relačními i NoSQL databázovými systémy.
	
	Cílem práce je prostudovat a podrobně popsat problematiku KDBS. Práce se zaměří na vysvětlení tohoto konceptu a identifikaci klíčových rozdílů mezi jednotlivými KDBS. Jednou z hlavních úloh práce je zmínit a detailně popsat některé z nejznámějších a nejčastěji využívaných databází v tomto odvětví. Tyto databáze budou vzájemně porovnány s důrazem na jejich vlastnosti, výhody a nevýhody. Dalším úkolem práce je příprava a zprovoznění testovacího prostředí, které umožní měření propustnosti a odezvy na dotazy těchto vybraných KDBS. Tento proces zahrnuje konfiguraci prostředí a zprovoznění databázových instancí, ať už lokálně nebo v cloudovém prostředí. Následně budou vybrané databáze podrobeny testování a budou měřeny jejich vlastnosti v reálném provozu. Naměřené hodnoty budou demonstrovány a analyzovány s cílem porovnat chování jednotlivých databází v různých scénářích a za různých podmínek. Konečné výsledky budou opětovně vzájemně porovnány, což umožní vyvodit závěry o tom, jak se jednotlivé databáze osvědčily v praxi při manipulaci s konkrétně zvolenými daty.
	
	První část práce (\ref{chapter:no-sql-ky-sys}) se zaměřuje na detailní představení několika klíčových KDBS, mezi které patří Redis, Riak KV, Aerospike a další. Každá z těchto databází je důkladně popsána, a to včetně analýzy jejich charakteristických vlastností a schopností. Tato část slouží k poskytnutí uceleného přehledu o jednotlivých KDBS, aby čtenář získal podrobný vhled do jejich fungování a možností. V závěru této části je provedeno srovnání jednotlivých databází na teoretické úrovni, což pomáhá porozumět jejich relativním výhodám a omezením.
	
	Třetí kapitola (\ref{chapter:3-test_environment}) se obecně věnuje popisu prostředí pro testování databázových systémů. Jsou zde konkrétně zmíněna a popsána dvě prostředí. Prvním je TPC, které je využíváno především pro relační databázové systémy, a druhým YCSB, jež je připraveno a vyvíjeno zejména pro NoSQL databáze. Každé z těchto prostředí je detailně rozebráno z hlediska svých funkcionalit, možností a účelu testování.
		
	Čtvrtá kapitola (\ref{chapter:4-test_results}) je věnována otestování a vyhodnocení výsledků čtyř vybraných KDBS, konkrétně Redis, Riak KV, Aerospike a Memcached. Tyto databáze byly vybrány pro analýzu z důvodu své relevance podle internetových žebříčků. Kapitola popisuje stroj, na kterém se KDBS testovaly, a potřebnou přípravu zvoleného testovacího prostředí YCSB a databází v Dockeru. Konkrétně se zde i popisují konfigurace jednotlivých testů, kroky pro úspěšné spuštění testů a samotné otestování. Kapitola je zakončena demonstrací výsledků naměřených hodnot při testování, vizualizací hodnot do grafů a vzájemným porovnáním hodnot jednotlivých KDBS mezi sebou. Z výsledného porovnání naměřených hodnot se sestaví závěr o tom, jak si jednotlivé KDBS vedly, v čem excelovaly a v čem naopak zaostávaly.

	
	\chapter{Key-value databázové systémy\label{chapter:no-sql-ky-sys}}
	
	V současné době existuje spousta různých KDBS, od malých open-source projektů po velké placené cloudové služby. Různé systémy disponují odlišnými vlastnostmi, jako je propustnost, škálovatelnost, uživatelská přívětivost skrze dotazovací jazyk a podpora atd. Dle průzkumu~\cite{predictiveanalyticstoday,g2,db-engineers-ranking} bylo vybráno 8 aktuálně významných KDBS, snažících se o jednoduchý popis, porovnání (\ref{tab_kvdb_compare}) a konečný výběr některých z těchto vhodných KDBS s cílem otestovat vlastnosti některých z těchto systémů.
	
	\section{Amazon DynamoDB}
	
	Amazon DynamoDB~\cite{dynamodb} je v současné době největší a nejvyužívanější KDBS. Jedná se o serverless cloud systém s odezvou v řádu jednotek mikrosekund a využitím v oblastech jako je web, technologie IoT, mobilní aplikace a herní průmysl. DynamoDB je plně a automaticky spravovatelná, multi-master databáze zaměřená na vysoké využití horizontální škálovatelnosti. Unikátní primární klíče umožňují identifikaci jednotlivých záznamů v tabulkách a sekundární indexy zlepšují dotazovací flexibilitu. Primární klíč slouží jako vstup do hashovací funkce a výsledný hash určuje fyzickou pozici uloženého záznamu. DynamoDB poskytuje silnou konzistenci při čtení hodnot od poslední aktualizace. Atomické čítače umožňují automatické změny hodnot číselných atributů. Pro expirované záznamy v tabulkách využívá tzv. TTL. Archivace dat je umožněna díky full backupu. Amazon DynamoDB rovněž nabízí VPC pro soukromou komunikaci bez nutnosti využití internetu.
	
	Databázový systém disponuje konzolovým API pro správu databáze a práci s daty, ale nabízí také možnost využití jazyka PartiQL~\cite{partiql}, který je vhodný pro kompatibilní SQL dotazy na schema-less databázích. DynamoDB API je rozděleno do čtyř hlavních částí. Kontrolní plán zahrnuje funkce spojené s vytvářením, úpravami, mazáním a získáním jmen všech tabulek. Dále umožňuje výpis podrobných specifikací dané tabulky, jako jsou primární klíče, indexy a nastavení propustnosti. Následuje datový plán, který poskytuje CRUD operace pro data v dané tabulce. S daty lze pracovat buď jednotlivě po záznamech, nebo pomocí Batch funkcí, které umožňují provést stejnou operaci nad desítkami záznamů najednou a dosáhnout tak vyšší propustnosti než při volání stejných funkcí pro jednotlivé záznamy opakovaně. Následně je možné provést Scan pro získání všech záznamů dané tabulky nebo indexu, případně Query pro získání hledané části dat. Třetí částí je DynamoDB Streams pro práci s časovými sekvencemi a práci s logy za posledních 24 hodin. Stream API poskytuje funkce pro výpis všech streamů, konkrétní popis daného streamu, získání iterátoru pro daný stream a nakonec získání jednoho záznamu z daného streamu. Poslední částí API jsou ACID transakce, které jsou rozděleny do dvou částí. První část je určena pro batch vkládání, úpravu a mazání záznamů a druhá část slouží k batch získání záznamů.
		
	\section{Oracle NoSQL Database}
	
	Oracle NoSQL Database~\cite{oraclenosqldb} je databázová cloud služba vhodná pro práci s velkými objemy dat a odhadovatelnou nízkou odezvou v řádu jednotek milisekund. Služba je postavena na enginu z Oracle Berkeley DB. Databáze je plně spravovatelná, flexibilní, škáluje horizontálně, dynamicky a dosahuje vysokých výkonů. Mimo Key-value data se jedná i o spolehlivé úložiště pro dokumenty a data s pevně daným schématem. Vzhledem k tomu, že databázový systém je plně spravovaný společností Oracle, tak je pro vývojáře rychlé a snadné začít tuto službu využívat a soustředit se pouze na vývoj aplikací, neboť není potřeba se obtěžovat se správou základní infrastruktury databáze, softwaru, zabezpečení atp. Jedná se o Single Master, Multi Replica grafový systém. Pokud dojde k chybě na masteru, je master automaticky nahrazen jednou z replik. Pro Key-value ukládání s kapacitu jednotek terabytů využívá systém velký počet Storage uzlů, které je možno skupinově konfigurovat. Pro udržení konzistence jsou Storage uzly replikovány. Uzly a hrany v grafu reprezentují entity které vytvářejí vztahy a propojení. Sdílený systém, uniformně alokuje data okolo ostatních částí skupin. Databáze obsahuje i SQL Query s jazykem pro import, export a přenos dat mezi různými Oracle NoSQL databázemi. Mimo jiné je zde podpora i pro Failover, SwitchOver, Bulk Get API, Off Heap Cache a podpora Big Data SQL.
	
	Restové API pro Oracle NoSQL Database je rozděleno do pěti částí. Správa indexů, která dovoluje vytvářet a mazat indexy pro danou tabulku. Tato část API také umožňuje zobrazit všechny indexy, které jsou pro danou tabulku vytvořeny a společně s detailním popisem každého indexu. Druhá část API se věnuje dotazům, umožňuje tedy syntaktickou kontrolu daného SQL dotazu, před připravení a spuštění dotazu. Třetí část je zaměřena na správu záznamů, obsahuje tedy CRUD funkce pro jednotlivé záznamy. Tato část ale neobsahuje funkci pro úpravu existujícího záznamu a ani neumožňuje správu mnoha záznamů najednou, pro úpravu je tedy nutno provést funkci odstranění záznamu a vložení nového a všechny záznamy je tedy také potřeba spravovat jednotlivě a postupně. Čtvrtá část je zaměřena správě tabulek, obsahuje možnost vytvoření, upravování, a mazání tabulek. Tato část také umožňuje výpis všech tabulek, informace o dané tabulce a využívání dané tabulky. Poslední část API se věnuje správě pracovních požadavků, lze zde zobrazit stav jednotlivých požadavků, mazat požadavky, získat chyby či log daného požadavku a list všech požadavků.
		
	\section{Redis} \label{lab-redis}
	
	Redis~\cite{redis} je in-memory úložiště pro datové struktury, využívané jako KDBS, cache, streaming engine nebo zprostředkovatel zpráv. Toto datové úložiště má skvělé využití pro klíče v podobě hashe a hodnoty jako velký JSON objekt. Pro persistenci dat můžeme ukládání dat na disk provádět po nastavitelných pravidelných intervalech, nebo je možné data logovat vždy při vykonávání operací. Pokud nemáme zájem o trvanlivost dat, je možné ukládání dat úplně vypnout a datové úložiště využít čistě jako cache. Úložiště škáluje horizontálně. Redis podporuje datové struktury jako řetězce, hashe, listy, množiny, bitmapy, hyperloglog a geospatial indexy. Nad datovými typy Redis umožňuje rychlé atomické operace, jako je rozšíření řetězců, přidání prvků na začátek a konec listů, atd. Datové úložiště také poskytuje seřazené množiny pro vytváření indexů dle ID nebo jiného číselného atributu. Redis hashing ukládá data jako klíč a mapu. Keyspace notifikace dovoluje klientům odebírat Publisher-Subscriber kanály. Pro práci s dotazy na souřadnice a geometrii je možné využívat Geo API. Redis umožňuje provádět transakce, volat Lua skripty a nastavovat různé úrovně TTL pro záznamy. Redis podporuje Trivial-to-setup Master-Slave asynchronního replikování, společně s rychlou neblokující se prvotní synchronizací. Struktura pro ukládání dat je single-rooted replikovaný strom. Redis má vlastní API pro práci s daty pro populární programovací jazyky jako C, Python, Java a JavaScript.
	
	S Redis databází lze pracovat například pomocí konzolového rozhraní, toto CLI~\cite{rediscli} poskytuje řadu jednoduše čitelných, ale netradičních příkazů pro práci s daty. Vždy potřebujeme specifikovat klíč, se kterým chceme v databázi pracovat. Pomocí příkazu SET a DEL vkládáme do databáze nebo mažeme jednotlivé hodnoty pro zvolený klíč. Příkazem GET získáme hodnoty pro daný klíč, případně můžeme zjistit, zda již existuje záznam pro daný klíč příkazem EXISTS. Pokud vyžadujeme práci s poli, tak můžeme pro daný klíč zleva i zprava vkládat hodnoty zřetězené v poli díky příkazům LPUSH a RPUSH. Obdobně odebíráme hodnoty z pole pomocí LPOP a RPOP, příkazem LRANGE vypíšeme hodnoty z pole a příkazem LLEN zjistíme počet jeho záznamů. Místo jednoduchých polí je možno pracovat i s množinami pomocí příkazů SADD, SREM, SISMEMBER a obdobně. Množiny mohou být i seřazené a pro ně se využívají příkazy jako ZADD. Pro práci se záznamy strukturovanými jako kolekce párů atribut-hodnota se využívá datový typ Hash, umožňuje nám pro daný klíč uložit záznam obsahující názvy atributů a jednotlivé hodnoty pro ně. Opět se zde využívají příkazy jako HSET a HGETALL pro nastavení a získání daného záznamu, případně HGET pro získání hodnoty daného atributu pro záznam na zadaném klíči. API obsahuje také příkazy pro ostatní datové typy, jako jsou bitmapy, geografické prostory, HyperLogLog a další.
	
	\section{Aerospike} \label{lab-aerospike}
	
	Aerospike~\cite{aerospike} je KDBS využívající Hybrid Memory architekturu~\cite{hybmem-arch}, která umožňuje odezvu v jednotkách milisekund a vysokou propustnost v řádech stovek tisíc až milionů operací za sekundu. Hybrid Memory architektura od Aerospike je implementována tak, že index je čistě In-Memory, tím pádem není index perzistentní (vhodné například pro uživatelské cache sessions), a data jsou uložena čistě perzistentně na SSD disku a čtou se přímo z něj. Díky tomu, že je Aerospike jako KDBS naprosto schena-less, je možné definovat Sets a Bins za běhu pro maximální flexibilitu aplikací. Databáze škáluje lineárně a poskytuje silnou konzistenci, nízkou cenu a korektnost. Umožňuje real-time analýzu pro rychlé rozhodování a dynamickou optimalizaci pro vhodné využívání zdrojů dat, proto je databáze vhodná pro velké a stále aktualizované databáze. Poskytuje server-side clustering a bezpečnost na transportní vrstvě. Databáze také umožňuje customer deployment s nulovým downtime. V praxi se Aerospike díky svým vlastnostem využívá například pro banking, telekomunikace, adtech a gaming. Aerospike poskytuje vlastní silný dotazovací jazyk AQL~\cite{aql}, který má prakticky shodnou syntaxi jako SQL (i když se o SQL nejedná). Vlastní vytvořitelné agregační funkce pomocí Lua jazyka jsou flexibilní pro agregační algoritmy.
	
	Dotazovací jazyk AQL se snaží zachovat standardní SQL syntaxi, obvyklé příkazy SELECT, INSERT, DELETE jsou tedy zachovány. Je možné vytvářet vlastní indexy nad tabulkami pomocí CREATE INDEX a provádět agregace pomocí AGGREGATE. Pro dotazy nad konkrétním záznamem specifikovaným pomocí hexadecimálního řetězce či Base64 lze v podmínce dotazu použít porovnání hodnoty s DIGEST nebo EDIGEST. Dotazování můžeme provádět i standardně nad primárním klíčem a ostatními atributy. Při vkládání záznamů lze specifikovat speciální datové typy atributů, jako je LIST, MAP, GEOJSON a další.
	
	\section{Oracle Berkeley DB}
	
	Oracle Berkeley DB~\cite{berkeleydb} je rodina vestavěných Key-value databázových knihoven. Jedná se o čistě In-memory databázi, díky čemuž dosahuje vysokého výkonu a odezvy v jednotkách mikrosekund. Databáze škáluje horizontálně. Data jsou replikována pro vysokou dostupnost z více zdrojů a dobrou toleranci chybovosti. Oracle Berkeley DB využívá vhodné datové struktury pro práci s daty, jako jsou B-strom, hash table indexy nebo fronta. Databáze využívá obnovitelné ACID transakce a poskytuje několik různých úrovní izolace (včetně MVCC~\cite{mvcc}). Data jsou dělena do oddílů dle key ranges. Umožňuje komprimaci dat. Databáze je Single-master, Multi-replica, tedy je vysoce dostupná a umožňuje dobrou konfigurovatelnost. Repliky umožňují čtecí škálovatelnost, rychlý fail-over, hot-standby a další distribuované konfigurace, dodávající podnikové prostředky v malém, vestavěném balíčku. Pro přístup k datům a nastavení databáze se využívá jednoduché volání funkcí API. Mnoho moderních programovacích jazyků, jako například C++, C\#, Java, Python atd., podporuje tyto knihovny. Data mohou být ukládána v nativním formátu aplikace, XML, SQL nebo jako Java objekty. Oracle Berkeley DB je vhodný nástroj pro vše od lokálního úložiště po world-wide distribuovanou databáze (od kilobytů po petabyty).
	
	Interakce s Berkeley DB SQL API je prakticky identická jako s SQLite~\cite{sqlite}. Pro práci s databází vytvořenou rozhraním BDB SQL~\cite{bdbsql} používáte stejná rozhraní API, stejné Shell prostředí, stejné příkazy SQL a stejné PRAGMA, jako se využívá u SQLite. BDB SQL rozšiřuje standardní SQLite PRAGMA o možnosti nastavení velikosti alokované paměti sdílených zdrojů, nastavení počtu bucketů v hashovací tabulce objektů zámků, zvolení soukromého prostředí místo sdíleného, přesměrování logování chyb do vlastního souboru, nastavení příznaku, který způsobí, že sdílené prostředky databáze budou vytvořeny ve sdílené paměti systému a další. Dalším drobným rozdílem je, že BDB SQL rozhraní nepodporuje klíčové slovo IMMEDIATE.
	
	\section{Riak KV} \label{lab-riak}
	
	Riak KV~\cite{riak} je distribuovaná KDBS s pokročilou lokální a multi-cluster replikací, která garantuje čtení a zápis i v případě selhání hardwaru nebo síťových oddílů. Riak využívá bezkonfliktní replikované datové typy (CRDT~\cite{crdt}), které umožňují nezávisle a souběžně aktualizovat jakoukoliv repliku v distribuované databázi se zajištěním sjednocení hodnot pomocí algoritmu, který je součástí samotného datového typu (flagy, registry, čítače, množiny a mapy). Poskytuje konfiguraci aktivního clusteru a dosahuje nízké latence v řádech jednotek milisekund díky dodávání dat z nejbližšího datacentra. Databáze rozděluje data z clusterů pro své dostupné zóny, má multi-cluster repliky a využívá redundance dat v geografickém regionu. Riak tedy automaticky distribuuje data skrz cluster pro robustnost a vysoký výkon. KDBS poskytuje flexibilní datový model bez předem definovaného schématu. Databáze má vylepšené logování chyb a reporty. Data jsou automaticky komprimována pomocí Snappy kompresní knihovny~\cite{snappy}. Databáze využívá master-less architekturu, je vysoce dostupná a má design horizontální škálovatelnosti. Škálovatelnost je téměř lineární při využití snadného přidání hardwarové kapacity bez nutnosti mnoha operací. Riak KV dovoluje zpracování dat pro analýzu a vyvození závěrů pro zlepšení chodu databáze. Riak KV je navržen pro nulové restrikce na hodnoty, takže session data mohou být enkódována mnoha způsoby a nevyžadují změnu schématu. Během nejvyšší zátěže nezhoršuje databáze zápis a horizontální škálovatelnost, uživatelé jsou stále obsluhováni bez problémů. Databáze je vhodná pro ukládání velkého množství nestrukturovaných dat, také pro big-data aplikace, ukládání dat z připojených zařízení a replikaci dat do okolí. Díky nízké latenci je databáze vhodná i pro chat/messaging aplikace. Riak KV exceluje v soukromém, veřejném či hybridním cloud nasazení.
	
	Riak KV API obsahuje všechny potřebné CRUD operace pro správu objektů. Při vytváření nových objektů je potřeba nastavit typ a název bucketu, který skladuje klíče a data do něj vložená. Bucket má také vlastní indexy pro vyhledávání dat uvnitř něj. Dva různé buckety mohou uchovávat stejnou hodnotu klíče, ale jeden bucket obsahuje pouze unikátní klíče. Klíč pro data lze specifikovat explicitně vlastní při vytváření objektu pomocí parametru nebo při jeho absenci je datům přiřazen náhodný klíč. Při vkládání dat do databáze můžeme jednoduše nastavit parametr TTL daného objektu a také počet jeho replik. Při čtení dat můžeme před získáním výsledku zadat minimální počet replik, které se musí shodnout na stejných datech pro zvolený klíč. Pro efektivnější dotazy lze vytvořit vlastní indexy pro výchozí nebo námi zvolená datová schémata. Lze se dotazovat na data pro zvolený klíč nebo provádět fulltextové vyhledávání. Databáze poskytuje i funkce pro tvorbu sekundárních indexů a následné dotazy nad nimi. Riak API také umožňuje hlubší nastavení autorizace a bezpečnosti, práci s replikami a řešení konfliktů.
	
	\section{Voldemort}
	
	Project Voldemort~\cite{voldemort} je distribuovaná KDBS založená na Amazon DynamoDB. Škáluje horizontálně pro čtení i zápis. Umožňuje zapojení storage engine (MySQL, Read-Only). Databáze automaticky replikuje data napříč servery pro dostupnost a bezpečnost jednotlivých oddílů při vysoké propustnosti, nicméně každý server obsahuje pouze část z celkových dat. Databáze je decentralizovaná z pohledu uzlů, každý uzel je samostatný a nezávislý, nenachází se zde žádný centrální řídící uzel nebo uzel řídící řešení chyb. Voldemort má výkon desítek tisíc operací za sekundu na jeden uzel (1 op. za 50 mikrosekund), samozřejmě závisí na hardwaru, síti, systému disku atp. Konzistence dat je nastavitelná (přísné kvórum nebo případná konzistence). Selhání serverů jsou ošetřována transparentně, pro lepší viditelnost, interní monitorování a validaci dat lze využívat JMX~\cite{jmx}. Data jsou verzována pro maximální integritu i během poruch. In-Memory caching pro eliminaci oddělených částí cache, jednoduché a rychlé in-memory testování (např. pro unit testy). Databáze umožňuje jednoduchou distribuci dat skrz stroje, data mohou být rozdělována například dle primárních klíčů. Databáze má hashovatelné schéma, vyhledávání dle primárního klíče a možnost modifikace jednotlivých hodnot. Voldemort poskytuje široké možnosti pro klíče i hodnoty díky serializaci včetně listů a tuplů s pojmenovanými poli. Pro serializaci (Java Serialization, Thrift, Avro) se v projektu Voldemort využívá JSON datový model v kompaktním bytovém formátu, a dochází k typové kontrole dat dle očekávaného schématu. Pomocí API je možné rozhodovat o replikování a umístění dat, nastavení různých strategií pro specifické aplikace a distribuci dat napříč datacentry, která mohou být geograficky velmi vzdálená. Nicméně, databáze Voldemort neposkytuje triggery, cizí klíče ani komplexní filtry pro dotazy.
	Project Voldemort~\cite{voldemort} je distribuovaná KDBS založena na Amazon DynamoDB. Škáluje horizontálně pro čtení i zápisu. Umožňuje zapojení storage-enginu (MySQL, Read-Only). Databáze automaticky replikuje data napříč servery pro dostupnost a bezpečnost jednotlivých oddílů při vysoké propustnosti, nicméně každý server obsahuje pouze část z celkových dat. Databáze je decentralizovaná z pohledu uzlů, každý uzel je samostatný a nezávislý, nenachází se zde žádný centrální řídící uzel nebo uzel řídící řešení chyb. Voldemort má výkonost desítek tisíc operací za sekundu na jeden uzel (1 op. za 50 mikrosekund), samozřejmě závisí na hardwaru, síti, systému disku atp. Konzistence dat je nastavitelná (přísné kvórum nebo případná konzistence). Selhání serverů jsou ošetřována transparentně, pro lepší viditelnost, interní monitorování a validaci dat lze využívat JMX~\cite{jmx}. Data jsou verzována pro maximální integritu i během poruch. In-Memory caching pro eliminaci oddělených částí cache, jednoduché a rychlé in-memory testování (např. pro unit testy). Databáze umožňuje jednoduchou distribuci dat skrz stroje, data mohou být rozdělována například dle primárních klíčů. Databáze má hashovatelné schéma, vyhledávání dle primárního klíče a možnost modifikace jednotlivých hodnot. Voldemort poskytuje široké možnosti pro klíče i hodnoty díky serializaci včetně listů a tuplů s pojmenovanými poli. Pro serializaci (Java Serialization, Thrift, Avro) se využívá JSON datový model v kompaktním bytovém formátu, probíhá zde typová kontrola dat dle očekávaného schématu. Pomocí API je možné rozhodovat o replikování a místech ukládání dat, nastavení různé strategie pro specifické aplikace a možnost distribuce dat skrz data centra která jsou mezi sebou geologicky velice vzdálená. Databáze neposkytuje triggery, cizí klíče ani komplexní filtry pro dotazy.
	
	Práce s Voldemort databází z pohledu klienta je přímočará, API se skládá pouze z pár základních funkcí pro správu dat. Tyto funkce jsou Put, Get a Del pro nastavení, získání a odstranění hodnot pro explicitně specifikovaný klíč. Funkce GetAll umožňuje obdržet více hodnot pro více specifikovaných klíčů pomocí volání pouze jedné funkce, GetAll dosahuje vyšší propustnosti než zřetězené volání samostatné funkce Get. Pro připojení k Voldemort databázi a nastavení výchozího uzlu úložiště se využívá funkce Bootstrap, bez nastavení výchozího uzlu je potřeba specifikovat uzel explicitně před každým voláním funkce Get a dalších. Pro funkci Bootstrap je také možné nastavovat serializer pro klíče i hodnoty, čas spojení klienta se serverem a interval automatické změny uzlu v rámci clusteru na ten nejvhodnější. Pro ukončení komunikace se využívá jednoduše funkce Close.
	
	\section{InfinityDB}
	
	InfinityDB~\cite{infinitydb} je NoSQL hierarchicky tříděná KDBS implementovaná v jazyce Java. Databáze má možnost využít čistě In-Memory ukládání dat, která je vhodné pro cache, nebo naopak se mohou data ukládat i perzistentně na disk do souboru, přičemž je možné měnit nastavení bez zasahování do kódu. Přístup k datům v cache je plně vícevláknový, využívá se většina jader, a data, která nejsou často využívaná, jsou stránkována na disk. Databáze dosahuje výkonu v jednotkách milionů operací za sekundu pro více vláknové operace v cache. Veškerá data a informace o databázi jsou uložena na disku v jednom souboru, což zajišťuje jejich aktuálnost a zároveň maximalizuje bezpečnost a korektnost. Databáze je designována právě pro použití jednoho kompletního souboru s okamžitým zotavením a nevyžaduje proto administraci. Databáze neobsahuje dodatečné konfigurační nebo dočasné soubory, upgrade skripty ani logy. Zotavení je bez logů o transakcích okamžité ihned po restartu. V databázi není potřeba dělat čištění junk souborů po operacích, když zde nejsou žádné zanechány. InfinityDB podporuje ACID pro vlákna a ACD pro bulk operace. Databáze poskytuje prostor pro ukládání strukturovaných, polostrukturovaných a nestrukturovaných dat. Tento jednoduchý model umožňuje ukládání vnořených Multi-values a je možné reprezentovat různé datové struktury, jako jsou stromy, grafy, key/value mapy, dokumenty, velká řídká pole a tabulky. Schema je možné měnit za běhu pro zpětnou i následující kompatibilitu. Data dotazů lze dynamicky sledovat pomocí set logic views, delta views a ranges. Databáze se využívá pro servery, pracovní stanice a příruční zařízení.
	
	InfinityDB poskytuje základní jednoduché API o deseti hlavních voláních. Funkcionalitu pro vkládání, úpravu a mazání hodnot zajišťují funkce Insert, Update a Delete. Funkce Delete je rozšířena o funkci Delete-suffixes, která umožňuje odstranit více hodnot v jednom volání. Pro získávání hodnot se využívá kurzoru, jehož pohyb v obou směrech zajišťují funkce First, Next, Last a Previous. Nakonec jsou k dispozici také potřebné funkce Commit a Rollback pro možnost využívání transakcí.

	\begin{sidewaystable}
		\centering
		\caption{Porovnání Key-value databází\label{tab_kvdb_compare}}
		\scalebox{0.8}
		{
			\begin{tabular}{ l|c c c c c c c c } 
				\toprule
				Databáze & Amazon & Oracle & Redis & Aerospike & Oracle & Riak & Voldemort & InfinityDB \\
				& DynamoDB & NoSQL DB & & & Berkeley DB & KV & & \\
				\midrule
				Čistě cloud & ano & ne & ne & ne & ne & ne & ne & ne \\
				Schéma dat & ne & ano i ne & ne & ne & ne & ne & ne & ano \\
				Licence & komerční & open source & open source & open source & open source & open source & open source & komerční \\
				Server OS & hostovaná & Linux, Solaris & Linux, Windows, & Linux & Linux, Windows, & Linux, OS X & Linux, Windows &  Linux, Windows, \\
				& & & OS X, BSD & & OS X, Android ad. & & & OS X, Solaris\\
				Napsáno v & - & Java & C & C & C, C++, Java & Erlang & Java & Java\\
				Sekundární & ano & ano & ano & ano & ano & omezené & ne & ne \\
				indexy & & & & & & & & \\
				Koncept & ACID & ACID & atomické, & atomické & ACID & ne & ne & ACID \\
				transakcí & & v rámci uzlu & izolované & & & & & \\
				Triggery & ano & ne & pub/sub & ne & ano & ano & ne & ne \\
				Dělící & sdílení & sdílení & sdílení & sdílení & ne & sdílení & ne & ne \\ 
				metody \\
				Replikační & ano & source-replica & source-replica, & volitelná & source-replica & volitelný & ne & ne \\
				metody & & multi-region & multi-source & faktor repl. & & faktor repl. \\
				Administrace & vysoká & nízká & vysoká & vysoká & vysoká & vysoká & vysoká & ne\\
				Škálovatelnost & horizontální & horizontální & horizontální & lineární & horizontální & lineární & horizontální & horizontální\\
				Odezva & mikrosekundy & milisekundy & milisekundy & milisekundy & mikrosekundy & milisekundy & milisekundy & milisekundy \\
				Dotazovací & PartiQL & Omezený SQL & Redis & AQL & SQL & Riak & Voldemort & InfinityDB \\
				jazyk & & & query & & & query & query & query \\
				\bottomrule
			\end{tabular}
		}
	\end{sidewaystable}
	
	\section {Nezmíněné významné NoSQL databáze}
	
		Do práce nebyly záměrně zahrnuty databázové systémy MongoDB a Couchbase~\cite{mongodb,couchbase}. I když se jedná o známé a hojně využívané NoSQL databáze, byly obě záměrně vynechány z práce, protože mají Key-value model až jako sekundární datový model. Primárně jsou určeny pro ukládání dokumentově orientovaných informací~\cite{documentdb}. Další často využívanou a nezmíněnou NoSQL databází je Cassandra~\cite{cassandra}, která udává jako datový model wide-column store~\cite{widecolumnstore}. Z tohoto důvodu byla i tato databáze vyřazena z testování.
	
	\chapter{Prostředí pro testování databázových systémů\label{chapter:3-test_environment}}
	
	Různé databázové systémy mohou přistupovat k řešení jednotlivých problémů odlišně. Pokud chceme rozhodnout, který z těchto systémů je nejvhodnější pro určité úkoly, musíme provést řadu testů a porovnání. Je prakticky nemožné nalézt ideální databázový systém, který by exceloval ve všech aspektech pro všechna data a případy využití. Testování nám však umožní odhalit, který systém vyniká a naopak zaostává pro konkrétní operace nad určitými daty. Proto je důležité najít ideální prostředí pro možnost měření a porovnání vlastností vybraných KDBS v kapitole~\ref{chapter:no-sql-ky-sys}.
	
	Existuje celá řada nástrojů pro měření výkonu databázových systémů. Mezi dva dosti známé a dostupné nástroje se řadí například TPC~\cite{tpc} a YCSB~\cite{ycsb}. TPC benchmarky od Transaction Processing Performance Council se dělí do mnoha kategorií. Například TPC-H je považován spíše za benchmark pro systémy pro podporu rozhodování~\cite{dss}, zatímco TPCx-BB je benchmark pro Big Data. Obecně se TPC benchmarky využívají spíše pro typické relační databázové systémy. Na druhou stranu Yahoo! Cloud Serving Benchmark (dále jen YCSB) od společnosti Yahoo! je open-source specifikace a sada programů pro vyhodnocování možností vyhledávání a údržby počítačových programů. Často se ale právě YCSB používá k porovnání relativního výkonu NoSQL databázových systémů, což je pro tuto práci zaměřenou na KDBS ideální. Proto byla tato technologie zvolena pro měření výkonu jednotlivých databázových systémů~\cite{benchmark-pdf-1, benchmark-pdf-2}.
	
	\section{YCSB} \label{lab-ycsb}
	
	YCSB architektura je založena na pluginech a poskytuje snadnou rozšiřitelnost pomocí skriptů. Pro značnou část významných databázových systémů existuje podpora v podobě bindingů. Samotný benchmark se skládá ze dvou fází. První z nich je Loading fáze zaměřená na vložení dat do databáze a následně druhá je Running fáze, ve které se spouští daný test (\ref{ycsb-blok-schema}).
	
	Při spouštění každého testu je možné nastavit určité parametry pro lepší konkretizaci měřeného scénáře~\cite{ytb-ycsb}. První a druhý parametr slouží pro specifikaci loading nebo running fáze a výběr testovaného databázového systému. Následně se vybírá testovaný scénář (Workload), počet záznamů v databázi, počet atributů daného záznamu, bytovou velikost každého atributu v záznamu, počet vláken, umístění serveru databáze a nakonec distribuci dotazů (uniformní, exponenciální, sekvenční, nejnovější, hotspot, definované).
	
	YCSB poskytuje 5 různých scénářů označených A až F pro testování propustnosti, odezvy a škálovatelnosti jednotlivých databázových systémů. Tyto pracovní scénáře, neboli Workloads~\cite{benchmark-pdf-1, workloads}, napodobují různé chování požadavků webových aplikací, jako jsou scénáře zaměřené výhradně na čtení, zápis nebo kombinace obojího. Konkrétní počet zvolených operací dle procentuální definice je vypočítán na základě parametru určujícího celkový počet operací daného scénáře. Při sekvenčním skenování ve Workloadu E je maximální počet skenovaných záznamů v jedné operaci definován jako 5\% z celkového počtu záznamů. Takže při počtu záznamů 1000 bude každá operace skenování číst právě 1 až 50 záznamů.
	
	\begin{itemize} \label{lab-workloads}
		\item Workload A (Update heavy)
		\begin{itemize}
			\item 50\% operací zaměřených na čtení a 50\% operací zaměřených na vkládání
		\end{itemize}
		\item Workload B (Read mostly)
		\begin{itemize}
			\item 95\% operací zaměřených na čtení a 5\% operací zaměřených na vkládání
		\end{itemize}
		\item Workload C (Read only)
		\begin{itemize}
			\item 100\% operací zaměřených na čtení
		\end{itemize}
		\item Workload D (Read latest)
		\begin{itemize}
			\item 95\% operací zaměřených na čtení, 5\% operací zaměřených na vkládání a poslední vložené záznamy jsou čteny přednostně
		\end{itemize}
		\item Workload E (Short ranges)
		\begin{itemize}
			\item 95\% operací zaměřených na sekvenční skenování nízkého počtu záznamů a 5\% operací zaměřených na vkládání
		\end{itemize}
		\item Workload F (Read-modify-write)
		\begin{itemize}
			\item každá operace se skládá z čtení daného záznamu, úpravy záznamu a následného vložení změněného záznamu zpět
		\end{itemize}
	\end{itemize}

	\begin{figure}
		\centering
		\includegraphics[scale=0.7]{Data/ycsb-1.jpg}
		\caption{YCSB rámec testování funkčnosti \cite{ycsb-parallel-data-lab}\label{ycsb-blok-schema}}
	\end{figure}

	\section{TPC}
	
	Transaction Processing Performance Council~\cite{tpc}, dále jen TPC, je společnost spravující software pro vytváření kvalitních benchmarků výkonnosti systémů pro online zpracování transakcí (OLTP)~\cite{oltp} a možnosti jejich následného monitoringu a porovnávání. TPC benchmarky poskytují spolehlivé testy pro velké firmy s přiměřenou zátěží, výsledkem benchmarků je počet transakcí za minutu (tpm).
	
	TPC benchmarky jsou rozděleny do více modelů pro různě specifikované testy. Prvním z modelů pro OLTP byl TPC Benchmark A (TPC-A), který následně nahradil benchmark TPC-B a aktuálně se v tomto odvětví využívá poslední generace OLTP benchmarků TPC-C a TPC-E. Například modely TPC-DS/DI a TPC-H jsou uzpůsobeny pro benchmark pro systémy pro podporu rozhodování~\cite{dss}. TPC benchmarky jsou přizpůsobeny i pro virtualizaci, IoT~\cite{iot} a další, viz tabulka TPC benchmarků (\ref{tab_tpc_modely}).
	
	Model TPC-C~\cite{tpc-c} simuluje velkoobchodní provoz s více sklady, známý jednoduše jako "společnost". V minimálním testu má společnost deset skladů, každý s deseti uživatelskými terminály. Každý sklad obsluhuje deset definovaných prodejních okrsků, každý s 3000 zákazníky, kteří objednávají podle katalogu výrobků o 100 000 položkách. Nejčastějšími transakcemi jsou objednávky zákazníků, přičemž každá objednávka obsahuje v průměru 10 položek, a platby zákazníků. Méně časté požadavky se dotazují na stav objednávek a skladových zásob, expedují objednávky a doplňují zásoby, které se sníží. Pro testování výkonnosti daného systému se počet skladů zvyšuje tak, aby splňoval požadované minimum potřebné k měření cílové úrovně výkonnosti.
	
	Výsledky srovnávacího testu se měří v transakcích za minutu, známých jako tpmC. První výsledek tpmC byl zveřejněn v září 1992 pro IBM AS/400 a přinesl výsledek 54 tpmC. V roce 2000 byl průměrný výsledek pro špičkové stroje 2,4 milionu tpmC a společnosti ve snaze získat rekord stavěly systémy velmi velkých rozměrů. Současný rekord byl stanoven v roce 2020 pomocí cloud computingu, který poskytl 707,3 milionu tpmC~\cite{tpc-c-top-result}. Nedávné výsledky pro menší lokální systémy se zaměřily na snížení nákladů na tpmC.
	
	\begin{table}
		\centering
		\begin{tabular}{ l | l }
			\toprule
			TPC benchmark & využití\\
			\midrule
			TPC-C, TPC-E & zpracovávání transakcí \\
			TPC-H, TPC-DS, TPC-DI & podpora rozhodování \\
			TPCx-V, TPCx-HCI & virtualizace \\
			TPCx-HS, TPCx-BB & velká data \\
			TPCx-IoT & IoT \\
			TPCx-AI & umělá inteligence \\
			TPC-Energy, TPC-Pricing & běžné specifikace \\
			TPC-A, TPC-B, TPC-APP, TPC-D & zastaralé benchmarky \\
			TPC-R, TPC-W, TPC-VMS & \\
			\bottomrule
		\end{tabular}
		\caption{TPC benchmarky\label{tab_tpc_modely}}
	\end{table}
	
	\chapter{Vyhodnocení výsledků testů\label{chapter:4-test_results}}
	
	\section{Testovací prostředí}
	
	Veškeré testy byly spouštěny na vlastním stroji, domácím počítači. Konkrétní specifikace tohoto stroje se nachází v tabulce  (\ref{tab_my_pc_spec}). 
	
	\begin{table}
	\centering
	\caption{Specifikace stroje na kterém se spouštěly testy\label{tab_my_pc_spec}}
		\begin{tabular}{ l | l | l } 
			\toprule
			komponent & název & podrobnosti \\
			\midrule
			OS & Microsoft Windows 10 PRO & x64 \\
			CPU & Intel Core i5 4590 & 3,3GHz (Boost 3,7GHz), core/thread 4, Haswell\\
			GPU & NVIDIA GeForce GTX 1660 SUPER & 6GB, 1530MHz (Boost 1785MHz) \\
			RAM & Crucial Ballistix Sport & 8GB (2x4GB), 1600MHz, DDR3 \\
			SSD & Samsung 870 EVO & R/W 560/530MB/s, 1TB, TLC, SATA 6Gb/s \\
			Základní deska & GIGABYTE GA-H81M-H - Intel H81 & 1150 socket, DDR3 DIMM \\
			\bottomrule
		\end{tabular}
	\end{table}

	\section{Zprovoznění testů}
	
	Pro rozsáhlé otestování byly vybrány čtyři vhodné KDBS. A to konkrétně Redis (\ref{lab-redis}), Riak KV (\ref{lab-riak}), Aerospike (\ref{lab-aerospike}) a Memcached. Všechny tyto zvolené databáze jsou v aktuálním roce 2024 hodnoceny jako jedny z nejlepších podle žebříčku na webu DB-Engines Ranking~\cite{db-engineers-ranking} právě pro testovaný model Key-value. Tento web přiřazuje databázím bodové hodnocení na základě četnosti nových článků o dané databázi na internetu, obecného zájmu, četnosti diskuzí na fórech, množství pracovních nabídek a poptávek a relevanci na sociálních sítích.
	
	Ve snaze o možnost replikace testů byly všechny databáze instalovány a spouštěny pomocí open-source platformy Docker~\cite{docker}. Bylo tedy nutné najít vhodné a kompatibilní docker images pro každou z testovaných databází. V kontextu této práce Docker pomáhá zrychlit zdlouhavou fázi instalování a nastavení počátečního stavu databází, udržení funkčnosti vybrané verze instalovaného softwaru a odstínění od stavu stroje, na kterém databáze spouštíme.
	
	Veškeré testy byly vytvářeny a spouštěny pomocí frameworku YCSB (\ref{lab-ycsb}). YCSB framework v první části, Load, do databáze vložil data, a následně v druhé části, Run, spustil testy a vrátil hodnoty výsledků. Pomocí přidání volitelných parametrů bylo možné testy upravit podle vlastních potřeb.
	
	Po spuštění databáze v Dockeru se k ní připojil YCSB framework, který následně prováděl testování nad zvolenou připojenou databází. Pro možnost komunikace bylo zapotřebí zprovoznit YCSB binding pro každou z databází, aby YCSB framework mohl úspěšně komunikovat se zvolenou databází, vložit data, spustit testy a vrátit patřičné výsledky.
	
	\section{Popis parametrů testů}
	
	Veškeré testy pro každou z testovaných databází byly spuštěny třikrát, a finální výsledek byl tedy průměrem ze všech tří testů pro každou databázi v dané testovací kategorii. Každý test byl spouštěn paralelně na čtyřech vláknech.
	
	Do databáze bylo vždy vloženo 100 000 záznamů a následující test prováděl 1 000 000 dotazů nad danou naplněnou databází. Následně byla databáze vyprázdněna, reinstalována a celý proces se opakoval ještě dvakrát.
	
	Testy byly prováděny ve třech YCSB kategoriích. Workload A (Update-heavy: 50\% read, 50\% update), Workload B (Read-mostly: 95\% read, 5\% update) a Workload C (Read-only) (\ref{lab-workloads}).
	
	Pro každý Workload a jednotlivé databáze byla vytvořena tabulka výsledků jednotlivých testů a výsledný průměr těchto testů. Mezi nejdůležitější výsledky testů patří celková doba trvání testu, propustnost a 95/99 percentil odezvy na operaci. V tabulce jsou také data o počtu spuštěných operací, průměrné odezvě na operaci, a také minimální a maximální doba odezvy na operaci.
	
	\section{Spouštěná testů}
	
	\section{Výsledky testů}
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}[scale=0.5]
			\begin{axis}[
				ylabel={Latency (ms)},
				symbolic x coords={Min,Avg,Max},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=4pt,
				bar width=24pt,
				x=6cm,
				%xmin=0,
				%width=15cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=4.3,
				xtick=data,
				%xmin=Min-15,
				%xtick distance=10,
				enlarge x limits=1.5,
				restrict y to domain*=0:5, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false,
				%extra x ticks={Min, Avg, Max},
				%x tick style={xticklabel style={xshift=-20pt}}
				]
				\addplot coordinates {(Min,0.3151666667) (Avg,0.830447166) (Max,47.92433333)};
				\addplot coordinates {(Min,0.317) (Avg,0.7842715474) (Max,28.53233333)};
				\addplot coordinates {(Min,0.4015) (Avg,0.9679028534) (Max,82.71366667)};
				\addplot coordinates {(Min,1.694) (Avg,4.058593436) (Max,163.0176667)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A - Latency (ms) Min Avg Max}
		\label{graph_Workload A - Latency (ms) Min Avg Max}
	\end{figure}
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentile Latency (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=8pt,
				bar width=12pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=2.5,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95\%,99\%},
				restrict y to domain*=0:3, % Cut values off at 14
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95\%,1.273) (99\%,1.9045)};
				\addplot coordinates {(95\%,1.12183) (99\%,1.5393)};
				\addplot coordinates {(95\%,1.3863) (99\%,1.8483)};
				\addplot coordinates {(95\%,6.757) (99\%,11.8656)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload A - Percentile Latency (ms)}
		\label{graph_Workload A - Percentile Latency (ms)}
	\end{figure}

	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentile Latency (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=8pt,
				bar width=12pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=3,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95\%,99\%},
				restrict y to domain*=0:3.5, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95\%,1.3236) (99\%,2.237833)};
				\addplot coordinates {(95\%,1.19283) (99\%,1.76783)};
				\addplot coordinates {(95\%,1.744) (99\%,2.832)};
				\addplot coordinates {(95\%,6.06766) (99\%,10.65033)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload B - Percentile Latency (ms)}
		\label{graph_Workload B - Percentile Latency (ms)}
	\end{figure}

	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ylabel={Percentile Latency (ms)},
				legend style={at={(0.5,-0.2)},
					anchor=north,legend columns=-1},
				every axis plot post/.style={/pgf/number format/fixed},
				ybar=8pt,
				bar width=12pt,
				x=4cm,
				y=1.5cm,
				ymin=0,
				axis on top,
				ymax=3,
				xtick=data,
				enlarge x limits=0.5,
				symbolic x coords={95\%,99\%},
				restrict y to domain*=0:3.5, % Cut values off at 3
				visualization depends on=rawy\as\rawy, % Save the unclipped values
				after end axis/.code={ % Draw line indicating break
					\draw [ultra thick, white, decoration={snake, amplitude=1pt}, decorate] (rel axis cs:0,1.05) -- (rel axis cs:1,1.05);
				},
				nodes near coords={%
					\pgfmathprintnumber{\rawy}% Print unclipped values
				},
				axis lines*=left,
				clip=false
				]
				\addplot coordinates {(95\%,1.21) (99\%,1.856)};
				\addplot coordinates {(95\%,1.24) (99\%,1.8616)};
				\addplot coordinates {(95\%,1.23) (99\%,1.6153)};
				\addplot coordinates {(95\%,3.71) (99\%,7.8856)};
				\legend{Redis,Aerospike,Memcached,Riak KV}
			\end{axis}
		\end{tikzpicture}
		\caption{Workload C - Percentile Latency (ms)}
		\label{graph_Workload C - Percentile Latency (ms)}
	\end{figure}
	
	\chapter{Závěr}
	
	TODO
		
	\nocite{*}
	
	\printbibliography[title={Literatura}, heading=bibintoc]
	
\end{document}